===== PARAGRAPH 1 =====
[Keyword detected: predictive maintenance]

--- Page 1 --- Reliability Engineering and System Safety 259 (2025) 110919 Available online 25 February 2025 0951-8320/(c) 2025 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies. Contents lists available at ScienceDirect Reliability Engineering and System Safety journal homepage: www.elsevier.com/locate/ress Deep learning-stochastic ensemble for RUL prediction and predictive maintenance with dynamic mission abort policies Faizanbasha A. a,b ,*, U. Rizwan a a Department of Mathematics, Islamiah College, New Town, Vaniyambadi, 635752, Tamil Nadu, India b Thiruvalluvar University, Serkkadu, Vellore, 632115, Tamil Nadu, India A R T I C L E I N F O Keywords: Predictive maintenance Prognostics and health management Smooth semi-martingale Degradation modeling Remaining useful life A B S T R A C T Accurate prediction of Remaining Useful Life (RUL) is crucial for optimizing maintenance strategies in industrial systems. However, existing models often falter under nonlinear and nonstationary degradation conditions with stochastic and abrupt failures, limiting their real-world effectiveness. To address this, we introduce a novel approach that combines advanced deep learning architectures with stochastic modeling and dynamic optimization techniques for more precise RUL prediction. This study has three overarching aims: First, to propose a hybrid ensemble model integrating convolutional neural networks, transformers, long short-term memory networks, and a smooth semi-martingale stochastic layer, a combination not previously explored, to effectively model both deterministic and stochastic degradation processes, thereby enhancing RUL prediction accuracy. Second, to introduce a reinforcement learning-based hyperparameter tuning method that dynamically adjusts model parameters, improving performance and reducing training time, which in turn optimizes the ensemble model's predictive capabilities. Third, to integrate the refined RUL predictions and time-varying thresholds into a multi-stage optimization framework for mission cycle assignment and resource management. This facilitates real-time decision-making and the development of a dynamic mission abort policy, including mission shifting, re-engagement, post-abortion analysis, mission plan adjustments, and maintenance scheduling. Together, these innovations enhance RUL prediction accuracy, model adaptability, and operational efficiency, ensuring reliable and cost-effective maintenance strategies in mission-critical systems. The proposed model, validated using NASA's C-MAPSS dataset, demonstrated superior RUL prediction accuracy over state-of-the-art methods, with sensitivity analyses and ablation studies confirming its stability and effectiveness. 1. Introduction Prognostics and Health Management (PHM) plays a pivotal role in predicting the future condition of industrial equipment. It enables timely Predictive Maintenance (PdM) decisions to reduce downtime and improve reliability [1]. Among the various metrics in PHM, Re- maining Useful Life (RUL) estimation provides a clear and quantifiable measure of the time left before system failure. This makes it essential for industrial applications [2]. In today's globally competitive indus- trial sectors, organizations are under constant pressure to maximize asset availability, reduce operational risks, and minimize costs [3]. At the same time, maintaining safety and regulatory standards are also equally important. Accurate RUL predictions serve as key indicators for scheduling maintenance activities, optimizing resources, and minimiz- ing unplanned failures. This, in turn, improves operational reliability and safety [4,5]. Advances in deep convolutional neural networks and *Corresponding author at: Department of Mathematics, Islamiah College, New Town, Vaniyambadi, 635752, Tamil Nadu, India. E-mail address: faizan_phdmaths@islamiahcollege.edu.in (Faizanbasha A.). LSTMs have shown great potential in enhancing the accuracy of data- driven RUL predictions. This is especially true for complex systems where expert models are not yet available [6]. While extensive research has focused on improving the accuracy of data-driven RUL predictions using deep learning methods such as CNNs and LSTMs, several key gaps still remain [7]. Firstly, existing models often fail to account for the stochastic nature of machine degradation, especially under nonlinear and nonstationary operational conditions found in complex industrial systems. Secondly, they struggle to handle abrupt failures and unpredictable shifts in degradation pat- terns, which are common in real-world applications. Thirdly, there is a lack of integration between advanced deep learning architectures and stochastic modeling techniques for RUL prediction. Lastly, current PdM strategies rarely incorporate dynamic mission abort policies necessary for real-time decision-making in mission-critical operations. https://doi.org/10.1016/j.ress.2025.110919 Received 5 October 2024; Received in revised form 12 February 2025; Accepted 14 February 2025 --- Page 2 --- Reliability Engineering and System Safety 259 (2025) 110919 2 Faizanbasha A. and U. Rizwan Nomenclature Acronyms & Abbreviations RUL Remaining Useful Life PdM Predictive Maintenance CNN Convolutional Neural Network LSTM Long Short-Term Memory network SSM Smooth Semi-Martingale RLHT Reinforcement Learning-Based Hyperparameter Tuning MDP Markov Decision Process RMSE Root Mean Squared Error ReLU Rectified Linear Unit TCN Temporal Convolutional Network C-MAPSS Commercial Modular Aero-Propulsion System Simulation PHM Prognostics and Health Management DQN Deep Q-Network AGCNN Attention-Gated Convolutional Neural Network Bi-LSTM Bidirectional Long Short-Term Memory network BiGRU Bidirectional Gated Recurrent Unit S-score Scoring function for RUL prediction RNN Recurrent Neural Network GRU Gated Recurrent Unit Notations X Raw sensor data Xcnn Output of CNN layer fCNN CNN function Fi,j Feature map in CNN W Filter weights in CNN b Bias term Ai,j Activation map after ReLU Xtrans Output of Transformer layer ftrans Transformer function Q, K, V Query, Key, Value matrices in Transformer dk Dimensionality of keys and queries Attention(Q, K, V) Attention function Xlstm Output of LSTM fLSTM LSTM function bi, bf, bo, bc Bias terms in LSTM Element-wise multiplication t State of the system at time tin SSM model g(s, s) Nonlinear degradation rate function (s, s) Volatility function Ws Standard Brownian motion (s, s-, z) Jump amplitude function N(d s, d z) Compensated Poisson random measure Mt Martingale component Hyperparameters of the model L() Loss function St State in MDP At Action in MDP Rt Reward function P(St+1|St, At) Transition probability in MDP (St) Policy in MDP Discount factor V*(St) Optimal value function Q(St, At) Action-value function Learning rate yi Target value in DQN () Loss function in DQN Failure threshold RULt Remaining useful life at time t t Dynamic threshold in mission abort policy Decay factor RULt Rate of change of RUL at Alert threshold Aj Current aircraft Ak Potential replacement aircraft Cshift Cost of shifting the mission Ccont(t) Cost of continuing the mission t Health state of an engine at time t r(s) Recovery rate re Threshold for re-engagement Cre(t) Re-engagement cost function Cmaint Maintenance cost Cfail(t) Expected failure cost topt Optimal re-engagement time Cmissed(t) Cost of lost mission opportunities U(Ak) Utility function for aircraft Ak Pfail(Ak, t) Probability of failure spare Threshold for shifting to spare role Bshift(t) Expected benefit of re-shifting Sre(t) Success probability if re-shifted Scont(t) Success probability if continued shift Threshold for re-shifting decision Ctotal(t) Total expected cost Mean of a distribution (e.g., in data normalization) S D Standard deviation of a distribution Risk tolerance T Time horizon Errori Prediction error for sample i To address these gaps, this study proposes a CNN-Transformer- LSTM-SSM ensemble framework designed to capture both deterministic and stochastic degradation processes. Deterministic degradation refers to predictable, gradual wear over time, while stochastic degradation involves random, unpredictable failures or sudden shifts in machinery condition [8]. By effectively modeling both types of degradation, our framework leads to more precise RUL predictions and mission-critical decision-making. The proposed stochastic layer within the ensemble model is based on the Smooth Semi-Martingale (SSM) framework. It captures both gradual wear and sudden degradation shifts [9]. This allows the model to handle unpredictable jumps and falls in degrada- tion processes that traditional and recent deep learning methods often overlook. This approach stabilizes the model performance and results in reduced error during RUL predictions. It enables for more reliable PdM scheduling and reduces the risk of unexpected equipment failures. A smooth semi-martingale is a special type of stochastic process that effectively models systems exhibiting both predictable trends and random fluctuations [9]. It combines deterministic elements, such as gradual wear, with stochastic components like sudden shocks or fail- ures [8,10]. In the context of our study, machinery degradation is complex and involves both steady wear and abrupt failures due to unforeseen factors. By including an SSM layer in our deep learning ensemble model, we enhance its ability to accurately reflect the com- plex nature of equipment degradation. This integration improves the model's performance in handling nonlinear and nonstationary degra- dation patterns, leading to more precise RUL predictions and better maintenance decisions. 1.1. Background and related works Recent advancements have integrated the data-driven probabilistic RUL prognostics into the maintenance scheduling. This has demon- strated significant reductions in unscheduled maintenance events and --- Page 3 --- Reliability Engineering and System Safety 259 (2025) 110919 3 Faizanbasha A. and U. Rizwan overall maintenance costs for aircraft systems. It shows the potential of deep learning and Monte Carlo-based approaches to improve predictive accuracy and decision-making [11]. The integration of AI-driven PHM systems further enhances predictive capabilities. By utilizing a com- bined approach of ''model-driven'' and ''data-driven'' methods, these systems can detect anomalies and predict RUL in complex engineering systems. This shows great promise in reducing unexpected failures and optimizing maintenance strategies [12]. Additionally, integrating multiple data sources within Industrial IoT (IIoT)-enabled systems can further refine the RUL predictions, improving accuracy and providing more informed decision-making in industrial applications [13]. Dynamic PdM approaches that use probabilistic deep learning mod- els has further improved the accuracy and efficiency of RUL prog- nostics [14,15]. This is particularly true for multi-component sys- tems, allowing for more precise maintenance scheduling under uncer- tainty [16]. Recent advancements in ''deep learning'' methods, such as attention-based ''temporal convolutional networks,'' have significantly improved the accuracy of RUL prediction by efficiently handling large- scale industrial IoT data [17]. Furthermore, the prediction of RUL has advanced through the development of deep learning techniques like the Multicellular LSTM (MGLSTM). This model effectively processes multi- source data for enhanced prediction accuracy in aerospace applications. It has demonstrated superior performance compared to traditional machine learning techniques [18]. In recent years, there has been significant advancement in PdM and RUL prediction using deep learning techniques. For instance, ''bidirec- tional gated recurrent units'' combined with ''temporal self-attention'' mechanisms have been proposed to improve the prediction accuracy of RUL in various industrial systems [19,20]. Approaches incorporating ''multi-head dual sparse self-attention'' networks [21], spatial-temporal attention-based LSTMs [22], ''dual-aspect self-attention'' based on Transformers [23], and Temporal Convolutional Networks (TCN) with attention mechanisms have shown improved prognostic performance. This is particularly evident in machinery systems [24,25]. Transformer based architectures have also been utilized by integrating trend aug- mentation and temporal features with multi-sensor data for RUL pre- diction [26]. ''Bayesian gated-Transformer'' models have been de- veloped for ''risk-aware'' prediction of aero-engine RUL [27]. Addi- tionally, aircraft engine RUL estimation via ''double attention-based data-driven architectures'' has been explored recently [28]. Moreover, improved Transformer models using feature fusion gates and predictive vector angle minimization have been proposed for aircraft engine RUL prediction, achieving higher accuracy and advanced prediction capabilities [29]. Other studies have focused on dynamic predictive maintenance scheduling using deep learning ensembles [30-32]. Additionally, data- driven approaches combined with sensor-based monitoring have been explored [33]. Hybrid CNN-LSTM models have also been developed for optimizing maintenance and production processes [34]. Recently, advanced techniques such as Bayesian-optimized LSTM for lithium-ion battery health prognostics [35] and soft-thresholding attention-based TCN for machinery prognostics [24] have been extensively studied. Further, multi-objective predictive maintenance scheduling models that integrate RUL estimations into maintenance decisions have also demon- strated significant improvements in maintenance completion time and cost reductions [36]. Lightweight models, such as dual attention LSTMs based on exponential smoothing, have also been proposed for RUL prediction [37]. Dual-task TCN models with multi-channel attention have also been developed to improve RUL predictions and identify the first failure time in complex systems [25]. These developments show the growing importance of integrating deep learning into prognostics to enhance PdM strategies. Moreover, recent studies have optimized maintenance processes by integrating burn-in, predictive maintenance, and smooth semi- martingale models, effectively reducing downtime and costs while enhancing reliability in manufacturing systems [10]. This demonstrates the effectiveness of combining stochastic processes with PdM strategies, supporting our ensemble framework that incorporates an SSM layer for both deterministic and stochastic degradation. Based on our review of the literature, we hypothesize that integrat- ing CNNs, Transformers, LSTMs, and an SSM stochastic layer into an ensemble model can effectively capture both deterministic and stochas- tic degradation processes. This integrated approach aims to address the limitations of existing methods by handling unpredictable shifts in degradation patterns and accounting for the inherent randomness in machine degradation. By doing so, we expect to enhance the accuracy and stability of RUL predictions, leading to more reliable predictive maintenance strategies in industrial applications. Mission abort policies are critical in preventing catastrophic failures and ensuring mission success, especially in safety-critical operations with uncertain conditions. Furthermore, recent advancements have significantly enhanced the development of dynamic mission abort poli- cies to improve system reliability and safety. Optimal two-stage abort policies have been proposed to balance mission progress with risk mitigation in performance-based missions [38]. Strategies addressing multi-component system failures with interactive failure modes have been developed to enhance system survivability [39]. Joint model- ing approaches that integrate loading and mission abort decisions in dynamic environments have also been explored to optimize system performance under varying conditions [40]. Additionally, policies op- timizing component activation and mission aborting in multi-attempt missions have demonstrated reductions in expected mission losses [41]. Time-varying and self-adaptive mission aborting policies have been introduced to handle resource constraints and uncertain shock envi- ronments effectively [42,43]. Reliability modeling for balanced systems considering mission abort policies has further advanced the under- standing of mission success probabilities and system survivability [44]. Moreover, joint optimization of mission abort strategies with system structures has been investigated to address dynamic tasks and enhance mission reliability [45]. Additionally, optimal condition-based abort decisions have been formulated to minimize expected total costs by integrating degradation processes with abort policies [46]. These stud- ies collectively contribute to the robust framework for mission abort policies, ensuring enhanced safety and reliability in diverse operational scenarios. 1.2. Research gap and motivation Despite the growing adoption of deep learning models in PdM, accurately predicting the RUL under real-world conditions remains a significant challenge [16]. Models like CNNs and LSTM networks capture the spatial and temporal patterns. However, they often fail to account for the stochastic and nonstationary nature of machine degradation, leading to less reliable RUL predictions [47]. Addition- ally, traditional hyperparameter tuning methods, such as grid search, Bayesian optimization, or manual adjustment, are inefficient and may not yield optimal model performance. There is also a gap in connect- ing RUL predictions with actionable maintenance strategies, such as dynamic mission abort policies that can make real-time operational decisions based on the predicted RUL. According to a systematic literature review, existing predictive maintenance models often lack integration of stochastic processes and dynamic mission abort policies, limiting their ability to accurately predict RUL under nonlinear and nonstationary degradation. Nonlinear degradation refers to the irregular, unpredictable wear of machinery components influenced by factors like load, temperature, or operational stress. Nonstationary degradation implies that the statistical properties of the degradation process changes over the time, challenging models that assume consistent wear patterns. In real-world scenarios, such degradation can lead to sudden, unforeseen failures, causing critical downtime and safety risks. These complex degradation behaviors ne- cessitate advanced methodologies capable of adapting to changing --- Page 4 --- Reliability Engineering and System Safety 259 (2025) 110919 4 Faizanbasha A. and U. Rizwan Fig. 1. The proposed framework for RUL prediction, pdm, mission cycle assignment, and dynamic mission abort policies. conditions. Further, the existing methods often lack reliable uncer- tainty quantification, a critical aspect in RUL prediction. For instance, a Gaussian process-based framework with active learning has been proposed to address this, but computational inefficiencies still remain a challenge [48]. To address these challenges, we propose a CNN-Transformer-LSTM- SSM ensemble framework that integrates a stochastic process layer based on the SSM model. This addition enables the model to capture both gradual wear and sudden failures, enhancing performance across varying operational conditions. The SSM layer is particularly effective in capturing unpredictable jumps and random shifts in degradation pat- terns, the aspects that traditional deep learning models often overlook. Additionally, we propose a new Reinforcement Learning-Based Hyper- parameter Tuning (RLHT) method to dynamically adjust key model parameters to further enhance performance and reduce the training time. The proposed approach was validated on the ''NASA C-MAPSS'' dataset [49]. The results demonstrate better performance in RUL pre- diction when compared to the recent and traditional ''state-of-the-art'' methods. Additionally, based on the predicted RUL, we propose a novel mission abort policy that uses dynamic, time-dependent thresholds, fa- cilitating real-time decision-making during mission-critical operations. This policy includes strategies for mission shifting, re-engagement, and post-abortion analysis to ensure operational continuity. To the best of our knowledge, this study is the first to propose such a hybrid framework that introduces an SSM layer within deep learning models. This addition captures both deterministic and random degradation processes, enhancing prediction stability and accuracy. Further, the relationships between the core components of our proposed framework are illustrated in Fig. 1. The framework integrates RUL prediction, PdM, mission cycle assignment, and dynamic mission abort policies. Specifically, RUL predictions from the deep learning layer inform pre- dictive maintenance decisions, optimize mission assignments to im- prove efficiency, and enable real-time mission abort decisions based on operational conditions and system health. 1.3. Main contributions The main contributions of this study are: 1. Proposing a Novel Hybrid Ensemble Model. We introduce a hy- brid CNN-Transformer-LSTM-SSM ensemble model that com- bines CNNs for spatial feature extraction, Transformers for cap- turing ''long-range temporal dependencies,'' LSTM networks for sequential modeling, and an SSM stochastic layer for handling stochastic degradation processes. This enhances the accuracy of RUL predictions in complex, nonlinear industrial systems. 2. Developing an SSM-Based Stochastic Layer. We develop a stochas- tic layer using the SSM model to capture both continuous wear and abrupt failure dynamics, addressing limitations of previous deep learning models and improving predictive accuracy under varying operational conditions. 3. Introducing Reinforcement Learning-Based Hyperparameter Tuning. We propose a reinforcement learning-based hyperparameter tun- ing method that dynamically adjusts key parameters during training, enhancing model accuracy and reducing training time compared to traditional methods. 4. Optimizing Mission Cycles Assignment and Resource Management. We integrate RUL predictions into a multi-stage optimization framework, enabling dynamic engine allocation, mission plan adjustments, and maintenance scheduling to minimize costs and mitigate failure risks under complex operational constraints. 5. Implementing a Dynamic Mission Abort Policy. We introduce a ''dy- namic mission abort policy'' based on time-varying thresholds to allow real-time mission adjustments. We also develop strategies for mission shifting, re-engagement, and post-abortion analysis to effectively manage mission-critical operations. The remainder of this paper is organized as follows. Section 2 outlines the methodology of the proposed CNN-Transformer-LSTM- SSM ensemble framework. In Section 3, we present the framework for predictive maintenance scheduling and mission cycle optimization based on the proposed ensemble model. Section 4 introduces a dynamic mission abortion policy informed by the predicted RUL, while Section 5 presents an analysis of post-mission abortion and aircraft shifting, focusing on maintenance and optimization considerations. Section 6 provides the experimental analysis, showcasing validation results using the NASA C-MAPSS dataset. Finally, Section 7 concludes the paper with a summary of our findings and suggestions for future research. --- Page 5 --- Reliability Engineering and System Safety 259 (2025) 110919 5 Faizanbasha A. and U. Rizwan 2. Methodology In this section, we explain the methodologies that integrates CNNs, Transformers, LSTM networks, and the smooth semi-martingale model to predict failures and estimate RUL in industrial systems. This ap- proach uses the strengths of deep learning and stochastic modeling to process complex sensor data and predicts machinery degradation dynamics. 2.1. Convolutional neural networks for spatial feature extraction In the proposed framework, Convolutional Neural Networks (CNNs) are employed to extract informative spatial patterns from the prepro- cessed sensor data. Initially, the raw sensor signals Xare normalized and segmented into fixed-size windows, Xsegment, ensuring that each segment captures localized operational states of the machinery. The CNN processes these segments through stacked convolutional layers, each applying a set of learnable filters to identify spatial cor- relations associated with machine health. For each filter W, a feature map Fis generated: Fi,j= M m=1 N n=1 Xi+m-1,j+n-1 Wm,n+ b, (1) where Mand Nare the dimensions of the filter and bis the bias term. Further, the wear and potential failures of the machine are captured by these feature maps. Nonlinear activation functions (e.g., ReLU) are then applied to enhance the model's capacity to capture complex, nonlinear degradation patterns: Ai,j= max(0, Fi,j). (2) Subsequent pooling operations reduce dimensionality and focus on the most critical features, effectively condensing large volumes of sensor data into a compact, high-level representation. The resulting output, Xcnn, provides spatially refined features that serve as a robust foun- dation for downstream temporal modeling stages. By preserving key spatial characteristics of the machinery's health state, the CNN outputs facilitate more accurate RUL estimation and inform the PdM decisions that follow. 2.2. Temporal feature modeling Following the spatial features extraction by the CNN model, the data is now fed for temporal feature modeling. For this, we use two layers, namely the Transformer layer and the LSTM layer. These layers keeps the most important features from the input time-series data. 1. Transformers: The Transformer layer focuses on identifying ''temporal features'' and ''long-term dependencies'' via a self- attention mechanism. Unlike approaches reliant on positional information, the vanilla Transformer effectively highlights key time steps and relevant patterns in machinery degradation data. The output of the CNN, Xcnn, serves as input to the Transformer: Xtrans = ftrans(Xcnn), where Xtrans is the Transformer output and ftrans denotes the Transformer function. The core of the Transformer's operation is the attention mechanism: Attention(Q, K, V) = softmax ( QKT dk ) V, (3) where Q, K, and Vrepresent the query, key, and value matrices, respectively, and dkis the dimensionality of the queries and keys. The Fig. 2 details the components of the Transformer architecture. 2. Long Short-Term Memory (LSTM): The LSTM layer processes the Transformer's output to capture longer sequential dependen- cies. The standard LSTM model is employed due to its reliability, lower computational demands, and broad applicability in se- quence tasks. By incorporating LSTMs, both recent and past information is maintained, improving RUL predictions: Xlstm = fLSTM(Xtrans), where Xlstm is the LSTM output and fLSTM is the LSTM function. The LSTM's internal operations are defined as: it= (Wxixt+ Whiht-1 + bi) ft= (Wxfxt+ Whfht-1 + bf) ot= (Wxoxt+ Whoht-1 + bo) ct= ftct-1 + itt anh(Wxcxt+ Whcht-1 + bc) ht= ott anh(ct), where it, ft, otare the input, forget, and output gates, ctis the cell state, and htis the hidden state at time t. Weight matrices Wxi, Wxf, Wxo, Wxcconnect inputs to gates/cell states, and Whi, Whf, Who, Whcconnect previous hidden states. Biases bi, bf, bo, bcadjust these connections. The sigmoid function () controls the gates, t anh updates the cell and hidden states, and the Hadamard product () performs element-wise multiplica- tion. Fig. 3 illustrates the two-layer LSTM architecture, each with 128 units and a dropout rate of 0.2. While both Transformers and LSTM networks effectively process time series data, integrating them utilizes their complementary strengths in capturing temporal dependencies. Transformers excel at modeling long-range dependencies through self-attention mechanisms, effectively identifying global temporal patterns regardless of their position in the sequence. However, they may not capture local temporal dynamics as precisely as recurrent networks. Conversely, LSTMs are specifically designed to handle sequential data and excel at capturing local patterns through their gated structure, which controls the flow of information over time. By combining Transformers and LSTMs, our model effectively captures both global and local temporal dependencies in the time-series data, enhancing its ability to represent complex degradation processes and leading to more accurate RUL predictions. 2.3. Smooth semi-martingale stochastic modeling In this section, we present the mathematical framework for the SSM model. This framework is designed to capture the changing be- havior of nonlinear and nonstationary degradation processes in indus- trial machinery. It enables precise and reliable predictions of RUL. As illustrated in Fig. 4, the model captures varying operational condi- tions and stochastic behaviors. Nonlinear trends, nonstationary vari- ance, and their combination (Fig. 4(a)-(c)) reflect complex real-world degradation processes. The system state at time t, denoted by t, is modeled as an SSM: t= 0 + t 0 g(s, s) d s+ t 0 (s, s) d Ws+ t 0 R (s, s-, z) N(d s, d z), (4) where 0 is the initial state of the system, g(s, s) represents a non- linear degradation rate function, (s, s) is the volatility function, modulating the intensity of the stochastic component represented by standard Brownian motion Ws, and (s, s-, z) denotes the jump ampli- tude function, with N(d s, d z) being the ''compensated Poisson random measure'' for jump events. Further, the martingale component Mtis decomposed into continuous and jump parts: Mt= t 0 (s, s) d Ws+ t 0 R (s, s-, z) N(d s, d z). --- Page 6 --- Reliability Engineering and System Safety 259 (2025) 110919 6 Faizanbasha A. and U. Rizwan Fig. 2. Transformer architecture. Fig. 3. LSTM structure. Fig. 4. Nonlinear and Nonstationary degradation processes. --- Page 7 --- Reliability Engineering and System Safety 259 (2025) 110919 7 Faizanbasha A. and U. Rizwan Fig. 5. Dynamic interaction of deterministic and stochastic influences in system state evolution. The degradation rate function g(s, s) = a(s) + b(s) f(s) captures environmental and operational effects by employing time-dependent coefficients a(s) and b(s), along with a nonlinear function f(s) tailored to machine characteristics. Concurrently, the stochastic component is modeled as a diffusion term driven by standard Brownian motion Ws, with volatility (s, s) = (s)exp((s)s). Here, (s) and (s) determine the scale and sensitivity of the volatility to the system state, reflecting the unpredictable nature of the degradation. Jumps are modeled by (s, s-, z) = (s, s-)h(z), linking jump impacts to pre-jump conditions via () and modeling jump size distribution through h(z). The Fig. 5 illustrates how deterministic (green dashed line) and stochastic (blue line) components combine in the SSM model. The deterministic part tracks baseline degradation, while the stochastic component captures variability and abrupt disruptions, such as the random shock observed at t 75. Their integration (red line) reflects real-world complexity, including times when the system state drops below acceptable thresholds (e.g., between t = 45 and t = 90), indicating elevated failure risks. The depicted confidence intervals and uncertainty regions quantify the model's predictive uncertainty, with increasing variability as the system experiences higher stochastic volatility, particularly after t= 90. These findings show the SSM model's capability to accurately capture nonlinear, nonstationary, and random influences, which are critical for precise RUL prediction. Parameter estimation procedure. Estimating the parameters = (a, b, , , , f , h) is critical for accurately modeling the degradation process. We utilize outputs from the LSTM network to inform initial estimates of g(s, s) and (s, s). Specifically, the LSTM outputs guide the fitting of degradation rates to the functional forms. For statistical estimation, we use Maximum Likelihood Estimation (MLE) on observed trajectories. Due to jump complexities, we discretize time into Nintervals, forming increments i= ti-ti-1 and a likelihood: () = N i=1 pi ( i|ti-1; ) , where piare transition densities approximated by Euler-Maruyama for the continuous part and compound Poisson processes for jumps. We implement the Expectation-Maximization (EM) algorithm (Al- gorithm 1) to handle latent variables associated with unobserved jump times and sizes. The E-step computes expected values of these latent variables given current parameter estimates and observed data. The M-step maximizes the expected complete-data log-likelihood with re- spect to . This iterative process continues until convergence, yielding estimated parameters that best fit the observed data. Algorithm 1 Expectation-Maximization Algorithm for Parameter Estimation in the SSM Model 1: Input: Observed states {ti}N i=0, initial parameter guess (0) = (a, b, , , , f , h), convergence threshold 2: Output: Estimated parameters * 3: Preprocessing: Discretize the time interval into {ti}N i=0; form increments i= ti-ti-1 . 4: Initialize (0) (e.g., via LSTM-informed degradation rates or domain knowledge) 5: k-0 6: repeat 7: E-step: (Expected Sufficient Statistics) 8: 1. Compute latent jump-related statistics (e.g., expected jump counts, sizes) given (k). 9: 2. Evaluate the expected complete-data log-likelihood E[log (|, latent)]. 10: M-step: (Parameter Update) 11: 1. Maximize the expected complete-data log-likelihood w.r.t. to obtain (k+1): (k+1) -ar g max E[log (|, latent)]. 12: 2. Update model functions g(s, s), (s, s), and (s, s-, z) using new parameter values. 13: k-k+ 1 14: until ||(k) -(k-1)|| < or maximum iterations reached 15: Return: *-(k) 2.4. Reinforcement learning-based hyperparameter tuning In this section, we propose a new hyperparameter tuning method based on reinforcement learning. Determining the optimum set of hyperparameters gives the best prediction accuracy in deep learning models. Traditional methods, such as grid search or Bayesian optimiza- tion, are often static and do not adapt to changing conditions during training. But RLHT adapts to changes during the training and test periods. This method treats the tuning process as a decision problem. Objective: Minimize the prediction error L(), where Lrepresents metrics like RMSE or MAE. *= ar g min L(). (5) In this paper, we model the optimization of hyperparameter tuning problem under RLHT as a ''Markov Decision Process (MDP)''. 2.4.1. Markov decision process (MDP) formulation The State Space St consists of the current hyperparameters t = (1,t, 2,t, ... , n,t) and performance metrics Pt, defined as St= (t, Pt). The Action Space Atmodifies one or more hyperparameters, where i,tis updated as i,t+1 = i,t+ i,t. The Reward Function Rt measures performance improvement; for minimization, Rt= -L(t) = -(L(t+1) -L(t)). The Transition Probability P(St+1|St, At) describes the likelihood of reaching St+1, influenced by the model's response to updated hyperparameters. Finally, the Policy (St) determines action selection to find the optimal policy *that maximizes cumulative rewards. --- Page 8 --- Reliability Engineering and System Safety 259 (2025) 110919 8 Faizanbasha A. and U. Rizwan Table 1 Performance comparison of Bayesian optimization and RLHT. Method MAE (lower is better) RMSE (lower is better) Tuning Time (hours) Bayesian Optimization 12.34 15.67 5.4 RLHT 10.12 13.45 3.5 2.4.2. Reinforcement learning algorithm The goal of the RL algorithm is to determine the optimal policy * that maximizes expected cumulative rewards: Gt= E [ T k=t k-tRk ] , (6) where is the ''discount factor'' (0 <= < 1), which balances immediate and future rewards. Bellman Equation. The ''optimal value function V*(St)'' is: V*(St) = max At [ Rt+ St+1 P(St+1|St, At)V*(St+1) ] . (7) This equation forms the basis of dynamic programming solutions like ''Q-Learning'' or ''Deep Q-Networks (DQN),'' which approximate V*(St) to derive the optimal policy. Q-Learning Algorithm. Q-Learning uses the action-value function Q(St, At) to estimate expected rewards for choosing action Atin state Stand following the optimal policy thereafter. The update rule is: Q(St, At) -Q(St, At) + [ Rt+ max A' Q(St+1, A') -Q(St, At) ] , (8) where is the learning rate. The optimal policy is: *(St) = ar g max At Q(St, At) (9) Deep Q-Network (DQN). For large state-action spaces, a DQN ap- proximates Q(S , A; ) with a neural network. The loss function for training the network is: () = E [( Rt+ max A' Q(St+1, A'; -) -Q(St, At; ) )2] , (10) where -is the target network parameters. The Algorithm 2 outlines the RLHT process, which iteratively ad- justs hyperparameters to optimize model performance. Algorithm 2 Reinforcement Learning-Based Hyperparameter Tuning (RLHT) 1 Input: State space , Action space , Discount factor , Learning rate , Initial Q-network parameters , Target network parameters -, Replay buffer , Batch size B 2 Output: Optimal hyperparameters * 3 Initialize Q-network with and target network -- 4 Initialize replay buffer 5 for each episode = 1 to Ndo 6 Initialize state S0 7 for each time step t= 0 to Tdo 8 Select action Atvia -greedy policy: At= { random action with probability ar g maxAQ(St, A; ) otherwise 9 Execute action Atto adjust hyperparameters and train the predictive model 10 Observe reward Rtand new state St+1 11 Store transition (St, At, Rt, St+1) to 12 Sample mini-batch of Btransitions (Si, Ai, Ri, Si+1) from 13 Set target for each mini-batch transition: yi= Ri+ max A' Q(Si+1, A'; -) 14 Perform a gradient descent step on the loss function: () = 1 B B i=1 [yi-Q(Si, Ai; )]2 15 Update --every Csteps 16 Update state St-St+1 17 end for 18 Decay to reduce exploration over time 19 end for 20 Return Optimal hyperparameters *corresponding to the best observed performance To evaluate the effectiveness of RLHT, we compare it with Bayesian optimization in terms of MAE, RMSE, and tuning time. Table 1 presents the comparison results of RLHT and Bayesian optimization. Here, the Bayesian Optimization performed 50 iterations, while RLHT conducted 30 iterations. The different number of iterations is justified by RLHT's faster convergence, allowing it to achieve superior performance with fewer trials. Both methods tested multiple com- binations of learning rates ([0.00001, 0.01]), dropout rates ([0.1, 0.5]), CNN filters ([32, 128]), and LSTM units ([32, 128]). Exploring a wide range of hyperparameter combinations involves substantial training overhead at each iteration, and our integrated CNN-Transformer-LSTM- SSM framework requires more computational steps per trial to capture both deterministic and stochastic degradation dynamics. Although the reported tuning times, 5.4 h for Bayesian Optimization and 3.5 h for RLHT may appear substantial, they reflect the complexity of testing a comprehensive hyperparameter space and training the integrated CNN-Transformer-LSTM-SSM model repeatedly on the NASA C-MAPSS FD001 dataset. Despite these tuning times, RLHT achieved lower MAE and RMSE compared to Bayesian Optimization, demonstrating that the additional computational effort translates into significantly improved RUL prediction performance. As this process is performed offline, the final deployment of the predictive maintenance framework remains unaffected in real-time operations. Crucially, RLHT's faster convergence and superior accuracy (lower MAE and RMSE) underscore the benefits of this more targeted search approach. 2.5. CNN-transformer-LSTM-SSM ensemble method This subsection introduces an ensemble approach that integrates CNN, transformers, LSTM networks, and the SSM model. The ensemble method uses the complementary strengths of these individual compo- nents to enhance the prediction of machinery failures and to improve the estimation of RUL. 2.5.1. Ensemble architecture The proposed ensemble model functions as follows: CNN layers initially captures the ''spatial features'' from the input data, which are then forwarded to a Transformer module for capturing long-range dependencies. The LSTM component further refines temporal patterns, while the SSM layer provides stochastic modeling for more accurate and reliable predictions. The architecture of the proposed ensemble model for RUL prediction and PdM is presented in Fig. 6. 2.5.2. Training process and system configuration The training of the CNN-Transformer-LSTM-SSM ensemble follows a sequential approach to effectively capture spatial, temporal, and stochastic features. Preprocessing involves dropping irrelevant features (columns 0, 1, 2, 3, 4, 5, 9, 10, 14, 20, 22, 23 in the NASA C- MAPSS dataset) and normalizing the remaining data using Min-Max scaling. Time-series data is segmented into overlapping sequences (30 time steps, shift of 1-step) to preserve temporal dependencies. Each component CNN, Transformer, and LSTM is trained using supervised learning techniques. The CNN uses three Conv1D layers (filters: 64, 128, 64; kernels: 7, 5, 3) to extract localized spatial features. The Trans- former's multi-head attention mechanism highlights critical temporal elements, while two LSTM layers (128 units each, dropout 0.2) refine sequential patterns. Outputs are concatenated and passed through fully connected layers with ReLU activations, leading to a final output layer that predicts the RUL using a linear activation function. The ensemble is trained end-to-end using Adam optimizer (initial learning rate 0.0005) and optimized with RLHT model for parameters like learning rates, dropout, and attention settings. Early stopping with a patience of 10 epochs and learning rate reduction prevent --- Page 9 --- Reliability Engineering and System Safety 259 (2025) 110919 9 Faizanbasha A. and U. Rizwan overfitting. Regularization techniques like L2 weight decay and batch normalization improve stability. The SSM parameters are estimated via MLE to ensure accurate stochastic modeling. The entire training process is implemented using TensorFlow and Keras in Python 3.7 and executed on a high-performance computing system equipped with an Intel core i3 13th generation processor with 16 GB RAM, enabling efficient handling of large datasets and complex model architectures. 2.6. Remaining useful life prediction under the smooth semi-martingale model Predicting the RUL of industrial systems with high accuracy en- ables effective maintenance scheduling, failure prevention, and cost savings. We present an RUL prediction framework utilizing the SSM model, a stochastic process that separates random dynamics into deter- ministic and stochastic components. This model simulates machinery degradation and estimates RUL as follows: RULt= inf {u>=t:u>=} -t, (11) where RULtis the remaining useful life at time t, urepresents the system state at time u, and is the failure threshold. The state evolution tin the SSM model comprises deterministic and stochastic components (Eq. (4)), capturing both continuous degra- dation and sudden failures. To predict ufor u > t, we employ Monte Carlo simulations (Algorithm 3). These simulations generate multiple future paths of u, resulting in a distribution of RULt. Algorithm 3 Monte Carlo Simulation for RUL Prediction under SSM 1 Input: Current state t, failure threshold , model parameters g , , , time step t, total simulations K, max time Tmax 2 Output: Distribution of RUL estimates 3 Initialize an empty list for RULs: RULt-[] 4 for k= 1 to Kdo Monte Carlo iterations 5 Initialize u-t, (k) u -t Set initial state and time 6 while (k) u < and u<=Tmax do Check threshold or max time 7 Compute drift: D-g(u, (k) u)t 8 Compute diffusion: B-(u, (k) u)W, W~(0, t) 9 Simulate jumps: N~Poisson(t) 10 Compute total jump: J-N j=1 (u, (k) u, zj), zj~(z) 11 Update state: (k) u+t-(k) u + D+ B+ J 12 Increment time: u-u+ t 13 end while 14 if (k) u >=then 15 Compute RUL for this simulation: RUL(k) t -u-t 16 else 17 RUL(k) t -Tmax -t Max time reached 18 end if 19 Append RUL(k) t to RULt 20 end for 21 Return: Compute statistics: mean, variance, and confidence intervals of RULt Each simulation updates the system state (k) u through drift (D), diffusion (B), and jumps (J). Drift represents deterministic degra- dation, diffusion captures random fluctuations (W~(0, t)), and jumps model sudden failures using Poisson (N) and jump size distribu- tion ((z)). The simulation stops when (k) u exceeds or reaches Tmax, with RUL as u-t, generating a distribution of RUL estimates. Model performance is evaluated using RMSE for RUL predictions and accuracy for failure detection, with cross-validation to prevent overfitting. In Algorithm 3, each Monte Carlo iteration corresponds to one of the Kindependent simulations that generate a potential future degradation path for the system state t. By repeatedly simulating the drift, diffusion, and sudden jump components of the SSM model, the algorithm produces multiple prospective trajectories of u. This yields a distribution of RUL estimates, rather than a single determin- istic value, thereby quantifying uncertainty in how rapidly the system may degrade. The purpose of this Monte Carlo algorithm is twofold: (1) to capture the inherent variability and randomness in the degra- dation process, and (2) to provide statistical measures (e.g., mean and confidence intervals) for the RUL prediction. This distribution-driven approach is crucial for more robust decision-making in prognostics, as it enables maintenance strategies to account for worst-case scenarios, sudden failures, or extended lifetimes that deterministic models might overlook. The SSM-based RUL prediction framework is illustrated in Fig. 7. Representation of uncertainty in RUL predictions. Integrating the SSM model with the deep learning framework explicitly models the uncer- tainty in RUL predictions. The stochastic components (s, s) d Wsand (s, s-, z) N(d s, d z) capture random fluctuations and sudden degrada- tion jumps, respectively. By simulating multiple tpaths using esti- mated parameters, we derive a distribution of degradation trajecto- ries and corresponding RUL estimates. This probabilistic framework quantifies RUL uncertainty and enables the construction of confidence intervals, supporting risk assessment and decision-making in predictive maintenance. 3. Predictive maintenance scheduling and mission cycle optimiza- tion 3.1. Predictive maintenance scheduling In this section, we present a PdM scheduling framework that uses raw sensor data and our proposed ensemble model to forecast the RUL of machinery. 3.1.1. Predictive model integration for maintenance scheduling The ensemble model preprocesses sensor data Xthrough normaliza- tion and segmentation, followed by CNNs extracting spatial features: Xfeature = fCNN(fPreprocess(X)). Transformers capture long-range tempo- ral dependencies: Xtemporal = ftrans(Xfeature), which are further refined by LSTMs: Xlstm = fLSTM(Xtemporal). The SSM layer models the system state twith deterministic trends and stochastic fluctuations as: t= 0 + t 0 g(s, s, Xtemporal) d s+ Mt, where Mt = t 0 (s, s, Xtemporal) d Ws+ t 0 R (s, s-, z, Xtemporal) N(d s, d z). This model provides real-time health assessments, enabling the maintenance scheduling algorithm to optimize maintenance timing based on predicted RUL and failure probabilities. 3.1.2. Maintenance scheduling optimization Maintenance scheduling aims to minimize the total cost of mainte- nance and failure using predicted RUL and failure probabilities. Let denote the maintenance time. The optimal time opt is: opt = ar g min >=tE[C( , , RULt)], (12) where C( , , RULt) represents the cost associated with both mainte- nance, urgency of intervention, and failure. In accordance with stan- dard practice in reliability and maintenance theory, a distinct baseline maintenance cost is employed for identical maintenance actions. To explicitly account for the urgency of intervention as RUL decreases, we introduce: C( , , RULt) = cmaint + cscale exp(-k(RULt- (-t))) + cfail I{>=}. (13) Here, cmaint, cscale, and cfail represent the baseline maintenance cost, an urgency-based cost scaling term, and a failure penalty, respectively. The exponential term intensifies as the system approaches failure thresh- olds, signaling higher urgency for maintenance. This dynamic scaling captures real-world conditions, where delayed maintenance triggers emergency labor, secondary damage, and extended downtime, causing exponentially higher repair costs and operational risks. However, this scaling is optional; if cscale = 0, the cost function reduces to a standard cost model in reliability theory. The indicator function I{>=} imposes a penalty when the system's degradation exceeds the critical limit . The parameter kcontrols how rapidly the exponential cost rises as RUL decreases. By taking the expectation of C( , , RULt) over the --- Page 10 --- Reliability Engineering and System Safety 259 (2025) 110919 10 Faizanbasha A. and U. Rizwan Fig. 6. The proposed ensemble model architecture. Fig. 7. Remaining useful life prediction using While Loop under the SSM model. stochastic degradation process, we inherently capture the probabilistic nature of system failure. This ensures robust real-time scheduling in complex, uncertain environments. 3.1.3. PdM scheduling under the proposed ensemble model By continuously updating RUL predictions and expected costs, the PdM scheduling algorithm (Algorithm 4) triggers maintenance when RULt/falls below prescribed thresholds, adjusting opt as new data emerges. Each iteration acquires the current predicted RUL, evaluates maintenance and failure costs, and selects the opt minimizing total expected cost. Computationally, the core complexity arises from RUL prediction (handled efficiently by the trained deep model) and a sim- ple one-dimensional search for opt. Thus, the scheduling algorithm remains computationally tractable for real-time implementation. Algorithm 4 Predictive Maintenance Scheduling Based on Predicted RUL 1 Input: Predicted RULt, degradation state t, failure threshold , time horizon T, baseline cost cmaint, scaling parameter cscale, failure penalty cfail, exponential rate k, risk tolerance , model parameters 2 Output: Optimal maintenance schedule opt 3 Initialization: Initialize RUL0, 0, , , and 4 procedure Predict RUL 5 for t [0, T] do 6 Update RULt= fPredictiveModel(t; ) using sensor data. 7 Update degradation state taccordingly. 8 end for 9 end procedure 10 procedure Maintenance Decision 11 Set maintenance threshold thresh. 12 if RULt<=thresh then 13 Schedule maintenance at time t. 14 else 15 Compute risk: Risk = RULt . 16 if Risk < then 17 Trigger maintenance at time t. 18 else 19 Continue operations. 20 end if 21 end if 22 end procedure 23 procedure Cost Calculation 24 Compute cost at time : C( , , RULt) = cmaint + cscale exp ( -k(RULt- (-t))) + cfail I{>=}, where I{} is the indicator function. (Note: Setting cscale = 0 reverts to the standard cost model.) 25 end procedure 26 procedure Cost Optimization 27 For t [0, T], compute the expected cost: C(t) = E [ C(t, t, RULt) ] . 28 Determine the optimal maintenance time: opt = ar g min t[0,T] C(t). 29 end procedure 30 procedure Dynamic Adjustment 31 Continuously update RULtand twith new sensor data. 32 Recalculate C(t) and adjust opt as needed. 33 If significant deviations occur, trigger rescheduling. 34 end procedure 35 return Optimal maintenance schedule opt --- Page 11 --- Reliability Engineering and System Safety 259 (2025) 110919 11 Faizanbasha A. and U. Rizwan Practical applications of the PdM scheduling model. Integrating accurate RUL predictions into maintenance scheduling enables just-in-time ac- tions, minimizing costly downtime and preventing catastrophic failures. In high-stakes sectors such as aerospace, nuclear power, and pharma- ceutical production, data-driven maintenance enhances safety, extends equipment life, and ensures operational continuity. In manufacturing, PdM reduces unexpected breakdowns, optimizes production schedules, and improves efficiency. Similarly, energy, oil and gas, transportation, and healthcare benefit from precise strategies that boost system re- liability, streamline resource allocation, and ensure compliance with strict safety standards. By reducing downtime, optimizing inventory and manpower use, and improving operational efficiency, PdM delivers a competitive edge in cost-sensitive, risk-intensive global markets. The feasibility of the proposed PdM model is ensured through: (1) Computational Efficiency. The pretrained ensemble-based RUL pre- dictor enables rapid inference, while the one-dimensional optimization for opt keeps scheduling computationally lightweight. (2) Real-Time Implementation. Incremental sensor updates dynamically refine RUL and cost estimates, while seamless integration with the mission abort strategy ensures synchronized decision-making based on updated risk profiles. (3) Scalability and Adaptability. The modular design supports diverse systems by decoupling RUL prediction from scheduling, and adjustable parameters with dynamic recalibration allow customization for specific operational and risk requirements. 3.2. Mission cycles assignment and optimization based on the proposed ensemble model In mission-critical systems, such as aerospace operations, engines must be dynamically assigned to mission cycles comprising sequential segments with specific time windows, reliability requirements, and varying operational conditions. The proposed ensemble model provides accurate RUL predictions, enabling a scenario-based multi-stage opti- mization that reallocates engines, adjusts mission plans, and schedules maintenance to minimize overall costs and mitigate mission failure risks. 3.2.1. Mission cycle assignment Consider a set of missions = {M1, ... , Mm}, where each mission Mjconsists of Ljsegments (Mj ,1, ... , Mj ,Lj). Each segment Mj ,lis exe- cuted within the time window [tstart j ,l, tend j ,l] and requires a minimum RUL Dj ,lfor the assigned engine at tstart j ,l. The set of engines is denoted as = {E1, ... , En}. Uncertainties in mission loads, environmental factors, engine degradation, and resource availability are modeled through a scenario set , where P() is the probability of scenario . These scenarios reflect changes such as weather patterns, unplanned route adjustments, or delays in spare parts supply. We define binary variables xi,j ,l {0, 1} to indicate if engine Ei is assigned to segment Mj ,l, and continuous variables y j [0, 1] to represent the fraction of mission Mjcompleted under scenario . The objective is to minimize expected costs, including maintenance, fuel, and failure penalties. Let C i,j ,lbe the scenario-dependent cost of assigning engine Eito segment Mj ,l, and U jdenote the penalty for not completing mission Mj. The two-stage stochastic program is formulated as: min x,y P() m j=1 Lj l=1 n i=1 C i,j ,lxi,j ,l+ m j=1 U j(1 -y j) , (14) subject to: n i=1 xi,j ,l= 1 j , l, (15) RUL i,tj ,l>=Dj ,lxi,j ,l i, j , l, , (16) xi,j ,l {0, 1}, y j [0, 1]. Additional constraints incorporate mission-specific requirements. If a segment Mj ,ldemands high-thrust operations, the RUL must also sat- isfy an additional buffer D j ,l: xi,j ,l= 1 =RUL i,tj ,l>=Dj ,l+ D j ,l. (17) Engines in abrasive conditions, such as sandstorms, consume extra cycles h i,j ,l, constrained by scenario-dependent limits L i: m j=1 Lj l=1 h i,j ,lxi,j ,l<=L i. If engine Eilacks required certifications for segment Mj ,s, it cannot be assigned: xi,j ,l= 0 if Eilacks certification for Mj ,l. (18) Let tbe the maintenance crew capacity at time tunder scenario , and ithe crew workload for engine Ei. Then: n i=1 im i,t<= t, t, , (19) where m i,t {0, 1} indicates if Eiis scheduled for maintenance at time t. Further, engine assignments must not exceed available spares S: m j=1 Lj l=1 xi,j ,l<=S, i, . (20) 3.2.2. Mission operation and real-time monitoring During mission execution, the engine health state tevolves accord- ing to the SSM model: t= 0 + t 0 g(s, s) d s+ Mt, (21) where grepresents the deterministic degradation rate, and Mtmodels stochastic fluctuations and sudden failures. Real-time sensor data up- dates the RUL estimates RUL i,tfor each engine Ei. If t approaches a critical threshold , the model initiates immediate actions such as aborting a mission segment, rerouting missions, reallocating engine loads, or scheduling immediate maintenance. At each decision epoch t, the optimization problem (Eq. (14)) is re-solved with updated scenarios t, reflecting current engine health and mission status. By utilizing a receding horizon approach, the framework adapts to evolving condi- tions, reducing failures and associated costs while acknowledging that not all scenarios guarantee full mission completion. 3.2.3. Optimization and fine-tuning Let C maint,i,j ,l, C fuel,i,j ,l, and C fail,i,j ,lrepresent maintenance, fuel, and failure costs for engine i, segment j , l, and scenario , respectively. The total cost, including penalties pfor mission aborts, is defined as: Ctotal = m j=1 Lj l=1 n i=1 ( C maint,i,j ,l+ C fuel,i,j ,l+ C fail,i,j ,l ) xi,j ,l + m j=1 U j(1 -y j) + pI{Failures>'}, (22) The decision variables xi,j ,lensure that only selected actions contribute to the total cost. Operational penalties m j=1 U j(1 -y j) enforce mission completion, while pI{Failures>'} penalizes excessive failures, with ' representing the acceptable failure threshold. Parameter tuning minimizes the expected total cost across all scenarios : min P() (Ctotal( , ) + pI{Failures( ,)>'} ) . (23) This optimization balances operational costs with reliability and mis- sion success. Techniques such as scenario reduction, robust optimiza- tion, and decomposition enhance computational efficiency for large- scale problems. --- Page 12 --- Reliability Engineering and System Safety 259 (2025) 110919 12 Faizanbasha A. and U. Rizwan 3.2.4. Minimizing maintenance costs Maintenance scheduling optimizes the balance between scheduled and unscheduled maintenance to minimize total costs and operational downtime. The maintenance cost function is defined as: Cmaint = n i=1 (csch,imi+ cunsch,i(1 -mi)) , (24) where mi {0, 1} indicates whether engine Eiundergoes scheduled maintenance. Scheduled maintenance incurs a lower cost csch,i, while unscheduled repairs following unexpected failures are more costly, denoted by cunsch,i. To ensure maintenance is performed before critical degradation, we constraint: mi>= xi,j ,lh i,j ,l H i i, j , l, , (25) where H iis the maximum allowable wear for engine Eiunder scenario . This constraint links maintenance decisions mito usage-induced degradation h i,j ,l, ensuring maintenance is triggered when the risk of imminent failure increases. Additionally, to manage spare parts logistics, we impose: n i=1 simi<=S, t, , (26) where sirepresents the spare parts requirement for engine Eiand S denotes the spare parts capacity under scenario . 4. Dynamic mission abortion policy based on predicted RUL In mission-critical operations, deciding whether to abort a mission relies on accurate and timely RUL predictions [50,51]. Recent studies have refined mission abort strategies by incorporating multi-component failure interactions [39], adaptive policies for uncertain shock envi- ronments [43], and joint optimization with system structure to handle dynamic tasks [45]. The proposed dynamic mission abortion policy uses real-time RUL estimates from the CNN-Transformer-LSTM-SSM ensemble model, enabling informed decisions on whether to continue, adjust, or abort a mission. The RUL, denoted as RULt, is updated as: RULt= fLSTM(ftrans(fCNN(Xt))) + Mt, where Mtcaptures stochastic degradation dynamics. 4.1. Dynamic thresholds based on RUL Unlike static thresholds, the dynamic threshold tadapts to evolving system health and stochastic degradation patterns [52]. t= 0 exp(-(t-t0)) + (t), (27) where 0 is derived from mission-level reliability requirements, > 0 controls sensitivity to time and usage, and (t) represents stochastic variations. As tincreases, tdecreases, reflecting higher failure risks as components near end-of-life, as modeled by the SSM. Here, the term exp(-(t-t0)) aligns with the observed acceleration in failure probabilities for aging machinery, and (t) captures sudden jumps. This integration ensures that taccurately tracks the distribution of future states t, grounding the threshold in the same stochastic mechanics (SSM structure) that govern RUL estimation. The parameters 0, , and the properties of (t) are optimized using RLHT with historical run-to-failure data (e.g., NASA C-MAPSS). Specifically, is tuned to balance false alarms and missed detections, while (t) is modeled as a noise process through MLE to match empirical operational variance. These dynamic thresholds thus adapt to both deterministic drift and stochastic volatility, aligning maintenance actions with real-time risk assessments. 4.2. Continuous monitoring and preemptive alerts In this framework, continuous monitoring of the RUL enables timely preemptive alerts that prevent unexpected failures. The PdM closely tracks the RUL (RULt) and triggers alerts when it nears a dynamic threshold t. The rate of change of RUL, RULt = d(RULt) d t , serves as an early warning signal. An alert is issued if RULtexceeds a time-dependent threshold: at= a0 exp(-(t-t0)) + (t), (28) where a0 is the initial baseline, > 0 controls alert sensitivity over time, and (t) captures mission-specific conditions. SSM-based RUL predictions capture degradation increments from Brownian motion and Poisson jumps. The rate RULtreflects these changes, and comparing it to atidentifies abnormal surges. When RULt> at, it signals significant deviations from expected stochastic patterns, requiring immediate intervention. Practical implementation. When RULt> at, maintenance actions include: (1) Inspecting the engine for issues, (2) Reassigning tasks to healthier engines, and (3) Adjusting operational parameters to reduce degradation. The adaptable atminimizes false positives during stable periods while preventing failures that static thresholds overlook. More- over, the PdM model is integrated with the dynamic mission abort strategy through continuous real-time updates of RUL predictions and risk assessments. As the PdM model refines RUL estimates, it calculates the risk of failure, which is then communicated to the mission abort policy. If the predicted RUL falls below critical thresholds, the mission abort strategy triggers an abort decision to prevent failure. This interac- tion ensures that the PdM model drives maintenance scheduling, while the abort policy dynamically responds to evolving risk, maintaining system safety and mission success. Further, the Fig. 8 presents the decision process flowchart for the dynamic mission abort policy based on predicted RUL and associated costs. 4.3. Mission reallocation and optimization based on RUL When the predicted RUL of an aircraft engine is insufficient to safely complete a mission, the policy assesses whether to shift the mission to another aircraft. Let Ajrepresent the current aircraft and Aka potential replacement. The reallocation decision minimizes expected total cost, considering both transfer and operational expenses: Cshift = min k [ Ctransfer(Aj, Ak) + Coper(Ak) I{RULk,t>t} ] , where Ctransfer(Aj, Ak) is the transfer cost and Coper(Ak) the operating cost for the new aircraft. The mission is reassigned if: Cshift < Ccont(t) + Crisk(t), where Crisk(t) is the expected failure cost of continuing with the original aircraft. 4.4. Cost function and optimization We define the total expected cost of the mission, Ctotal(t), to capture the financial implications of continuing or aborting the mission based on the engine's RUL. The cost function is expressed as: Ctotal(t) = I{RULt<=t} (Cabort(t) + Cshift ) + I{RULt>t}Ccont(t). (29) When RULt<=t, the mission incurs the costs of aborting Cabort(t) and shifting to another aircraft Cshift, reflecting the need to mitigate failure risks. Conversely, if RULt> t, only the cost of continuing the mission Ccont(t) is incurred, representing ongoing operational expenses. By adjusting mission decisions based on the engine's health, this formu- lation ensures economically optimal outcomes and minimizes overall mission-related costs. --- Page 13 --- Reliability Engineering and System Safety 259 (2025) 110919 13 Faizanbasha A. and U. Rizwan Fig. 8. Dynamic mission abort policy flowchart. 5. Post-mission abortion and aircraft shifting analysis In mission-critical operations, analyzing the post-abortion phase can improve future cycle assignments, facilitate mission shifts to alterna- tive aircraft, and inform re-engagement strategies. By incorporating maintenance, re-engagement timing, spare aircraft management, and dynamic mission re-shifting, the decision-making framework becomes more resilient and cost-effective. 5.1. Post-abortion maintenance and re-engagement When an aircraft is aborted due to predicted failure or insuffi- cient RUL, it undergoes maintenance to restore its health. The post- maintenance health state maint(t) evolves as: maint(t) = init - t t0 r(s) d s+ (t), where init is the health at abortion, r(s) the recovery rate, and (t) captures stochastic delays. The aircraft can be re-engaged once maint(t) >=re, where re is the dynamic threshold indicating sufficient recovery to safely rejoin the mission. 5.2. Optimal re-engagement strategy For re-engaging a previously aborted aircraft to the same mission, we should account for both the risks of re-engagement and the potential benefits of mission completion. We define the re-engagement cost function as: Cre(t) = Cmaint + E [ Cfail(t) I{maint(t)<re} ] . (30) Now, the optimal re-engagement time topt that minimizes costs is: topt = ar g min t>=tready {Cre(t) + Cmissed(t)} . (31) Here, tready is the earliest time when maint(t) >=re and Cmissed(t) is the cost of lost mission opportunities during downtime. 5.3. Dynamic aircraft shifting and spare management When a secondary aircraft replaces the aborted one, decisions about retaining it as the primary asset or assigning it as a spare depend on its utility function: U(Ak) = Coper(Ak) + (1 -Pfail(Ak, t)), where Pfail(Ak, t) is the failure probability. If U(Ak) < spare, the aircraft is shifted to a spare role to reduce operational load. 5.4. Re-shifting and multi-aircraft optimization After maintenance, deciding whether to reassign the mission back to the original aircraft or continue with the secondary aircraft depends on the expected benefit of re-shifting: Bshift(t) = E [Sre(t) -Scont(t)] , where Sre(t) and Scont(t) are the success probabilities if re-shifting or continuing, respectively. The re-shift occurs if: Bshift(t) -Cshift(t) > shift, ensuring re-shifting improves mission success and justifies associated costs. 5.5. Cost optimization and final mission analysis To ensure that all decisions made post-abortion are optimal, the sys- tem continuously updates a total cost function Ctotal(t), which includes all possible costs associated with re-engagement, continued operation, and aircraft re-shifting: Ctotal(t) = Cre(t) + Coper(Ak, t) + Cshift(t). (32) We aim to minimize this cost function to complete the mission assign- ments in the most optimal and reliable way. Furthermore, it guides managers to make optimal decisions during the post-abortion phase. 6. Experimental analysis In this section, we evaluate the proposed ensemble model on NASA's C-MAPSS benchmark dataset, focusing on its performance across four subsets (FD001-FD004). We also analyze the proposed mission cycle assignment, dynamic mission abortion policy, and post-abortion main- tenance, demonstrating their effectiveness in optimizing operations, minimizing downtime, and reducing costs. 6.1. C-MAPSS dataset overview For prognostics and RUL prediction, the NASA C-MAPSS dataset is a widely used benchmark. It contains historical run-to-failure turbofan engine data. Each engine operates under three operational settings until failure. The dataset is divided into four subsets: FD001 (single condition, one fault mode), FD002 (multiple conditions, one fault mode), FD003 (one condition, multiple fault modes), and FD004 (mul- tiple conditions and fault modes), adding complexity and realism. In Fig. 9 (a), we illustrate the turbofan engine chassis including the --- Page 14 --- Reliability Engineering and System Safety 259 (2025) 110919 14 Faizanbasha A. and U. Rizwan Fig. 9. Turbofan rotation section. fan, Low-Pressure Compressor (LPC), High-Pressure Compressor (HPC), High-Pressure Turbine (HPT), Low-Pressure Turbine (LPT), and nozzle. The HPT extracts energy to drive the HPC, and the LPT extracts energy to drive the fan and LPC, all connected via a rotating shaft. The nozzle directs exhaust gases out of the engine, contributing to thrust. Fig. 9 (b) shows a side view detailing airflow through the inlet, com- bustion chamber, and exhaust, emphasizing internal rotation [53]. The C-MAPSS dataset, with about 265,256 data points across four subsets, includes training and testing data with true RUL values. It is a key PHM resource enabling development and evaluation of predictive models. Dataset Division and Model Training. For each C-MAPSS subset (FD001-FD004), the dataset consists of three subfiles: ''train_ FD001.txt'', ''test_FD001.txt'', and ''RUL_FD001.txt'' (similarly struc- tured for FD002, FD003, and FD004). Specifically, ''train_FD001.txt'' and ''test_FD001.txt'' record various operational and sensor parameters of the turbofan engine as detailed in Table 2, while ''RUL_FD001.txt'' provides the true RUL corresponding to the engines in ''test_FD001.txt''. The training data is further divided into 80% for training and 20% for validation to facilitate hyperparameter tuning and ensure robust model performance. During training, we employed the Mean Squared Error (MSE) loss function to optimize the model's predictive accuracy for RUL: MSE = 1 N N i=1 (RULpredicted,i-RULtrue,i )2 , (33) where RULtrue,idenotes the true RUL and RULpredicted,iis the pre- dicted RUL for the i-th sample. To enhance generalization and mitigate overfitting, an L2 regularization term is incorporated: = MSE + J j=1 ||j||2, (34) where is a hyperparameter governing the strength of regularization, jrepresents the model parameters (e.g., network weights) in the j-th layer, and Jis the total number of parameter sets in the model. This combined loss function ensures high predictive accuracy while prevent- ing overfitting, thereby enhancing the model's generalization to unseen data. As summarized in Table 2 and illustrated by the distributions in Fig. 10, each subset's unique conditions and fault modes pose distinct challenges. Despite these complexities, our ensemble model remains ro- bust, achieving low RMSE and S-scores and effectively handles diverse scenarios. 6.1.1. Analysis of nonlinear and nonstationary degradation in the C-MAPSS dataset To demonstrate nonlinear and nonstationary degradation patterns in the C-MAPSS dataset, we analyze degradation trajectories of multiple FD001 subset engines. Fig. 11 shows normalized degradation metrics over cycles for Engines #15, #27, #46, and #74, highlighting accel- erated degradation and increasing variance. The degradation metric, derived from sensor_11, is sensitive to engine health. For com- parison, readings were normalized to [0, 1] using min-max scaling. As shown in Fig. 11, these engines' degradation processes exhibit nonlinear and nonstationary characteristics: * Nonlinear Degradation: Each engine accelerates degradation after a specific cycle (e.g., cycle 160 for Engine #15), indicat- ing a nonlinear degradation rate. This suggests more aggressive wear mechanisms near failure, consistent with real-world factors like material fatigue and increased friction. Moreover, evidence from [49] supports this behavior, as damage propagation is mod- eled with exponential fault progression influenced by noise and operational variability, which can produce nonlinear shifts in observed health indices. * Nonstationary Variance: Degradation metric variability increases over time, especially in later operational cycles. This nonstationarity indicates that stochastic fluctuations become more pronounced as engines age, reflecting time-varying degradation dynamics. The C-MAPSS modeling approach incorporates process noise and operational variability, which inherently induce such characteristics, as described in [49]. Accelerated degradation points were identified by detecting significant changes in the local slope of the degradation metric using finite- difference methods and derivative analysis. Similarly, increasing vari- ance regions were marked by monitoring the evolution of the standard deviation of residual fluctuations over consecutive cycles. These ob- servations confirm that the C-MAPSS dataset exhibits nonlinear shifts and nonstationary variance, validating the CNN-Transformer-LSTM- SSM model. The Transformer layer captures temporal dependencies, while the SSM component manages stochastic fluctuations, ensuring accurate and stable RUL predictions. This approach achieves consis- tently lower RMSE and S-scores, improving prediction accuracy across evolving engine health states. 6.1.2. Performance evaluation metrics: RMSE and S-score In industrial machinery systems, accurately predicting the RUL can help the PdM to schedule maintenance optimally. Therefore, evaluating the predictions made by the model is important. For this, we consider ''two performance metrics,'' namely the ''RMSE'' and ''S-Score''. Root mean squared error (RMSE). The RMSE is a widely used regression metric that measures the average magnitude of prediction errors. It is particularly useful because it gives greater weight to larger errors, making it sensitive to outliers: RMSE = 1 n n i=1 (RULpredicted,i-RULtrue,i )2, (35) where nrefers to the total number of predictions. RULpredicted,idenotes the predicted RUL for the i-th data point, and RULtrue,iis the true RUL for the same i-th data point. The lower RMSE values indicate higher prediction accuracy between predicted and true RUL. --- Page 15 --- Reliability Engineering and System Safety 259 (2025) 110919 15 Faizanbasha A. and U. Rizwan Table 2 Details of the C-MAPSS dataset. Feature FD001 FD002 FD003 FD004 Number of Engines (Training) 100 260 100 249 Number of Engines (Test) 100 259 100 248 Operating Conditions One (Sea Level) Six One (Sea Level) Six Fault Modes One (HPC Degradation) One (HPC Degradation) Two (HPC Degradation, Fan Degradation) Two (HPC Degradation, Fan Degradation) Training Samples 20,631 53,759 24,720 61,249 Test Samples 13,096 33,991 16,596 41,214 Sensor Drift Patterns Minimal Varied across conditions Minimal Varied across conditions Operational Challenges Uniform Diverse due to multiple conditions Uniform Diverse due to multiple conditions Typical Failure Modes Compressor degradation Compressor & turbine faults Electronics failure, Compressor degradation Electronics failure, Turbine faults Fig. 10. Distribution of running cycles for subsets (FD001-FD004). S-score. The S-score is a specialized metric designed for predictive maintenance tasks where over-prediction and under-prediction of RUL have different consequences. It penalizes over-prediction more harshly because it can lead to catastrophic failures, while under-prediction, which leads to early maintenance, is less costly. S= n i=1 { exp(-Errori 13 ) - 1 if Errori>=0 exp( -Errori 10 ) - 1 if Errori< 0 (36) Where Errori= RULpredicted,i-RULtrue,i. * Over-prediction (Errori>=0): Overestimates of RUL are penal- ized more harshly, reflecting the critical risk of failures during operation. * Under-prediction (Errori< 0): The under-prediction of the RUL is less severe. It may waste some of the RUL, leading to some economic loss. The S-score is a metric that balances these two predictions. That is, lower S-score means the model is more balanced to these predictions, minimizing both premature and late maintenance actions. Evaluation procedure. The main steps for applying the proposed ensem- ble model to the CMAPSS dataset are as follows: 1. The ensemble model is trained using the training data contained within each of the subsets (FD001-FD004). 2. The trained model is then applied to the test dataset to estimate the RUL for the engines. 3. Finally, the values RULpredicted,iand RULtrue,iare substituted in Eqs. (35) and (36) to calculate RMSE and S-score, respectively. Now, the Table 3 summarizes the optimal hyperparameters for datasets FD001 to FD004. The Fig. 12 compares the true RUL and predicted RUL across subsets FD001 to FD004, highlighting prediction accuracy and error ranges. The Table 4 compares the RUL prediction performance across different ''state-of-the-arts'' methods, highlighting the RMSE and S-score for each subset (FD001 to FD004). 6.2. Sensitivity analysis of key parameters Analyzing the impact of hyperparameters on model performance is important to refine the ensemble model. For this, a sensitivity analysis was conducted on the C-MAPSS FD001 dataset, focusing on window size and learning rate. Using the proposed RLHT algorithm, we varied one parameter while fixing others, identifying hyperparameters that --- Page 16 --- Reliability Engineering and System Safety 259 (2025) 110919 16 Faizanbasha A. and U. Rizwan Fig. 11. Degradation trajectories of multiple engines from FD001 dataset, highlighting nonlinear acceleration and nonstationary variance. Table 3 Optimal hyperparameters used in the model configuration for different datasets. Hyperparameter Description Dataset FD001 FD002 FD003 FD004 Learning Rate Regulates the magnitude of the steps taken during gradient descent optimization. 1.0852e-05 5.7721e-04 3.9337e-05 4.1333e-04 Batch Size Number of samples processed before the model is updated. 64 64 64 64 Epochs Number of times the entire dataset is passed through the model. 65 121 72 114 Dropout Rate Probability of dropping a neuron during training for regularization. 0.4897 0.2453 0.2796 0.4845 Sequence Length Length of the input sequence for the model. 30 30 30 30 Window Length Length of the window used for input data processing. 30 30 30 30 Shift Number of time steps the window is shifted over the data. 1 1 1 1 Early RUL Maximum RUL value assigned to engines. 125 125 125 125 CNN Filters (1st Layer) The total filters used in the first convolutional layer. 114 109 53 119 CNN Filters (2nd Layer) The total filters used in the second convolutional layer. 155 207 191 110 CNN Filters (3rd Layer) The total filters used in the third convolutional layer. 123 69 115 75 CNN Kernel Size Size of the convolutional kernel in each layer. 3, 5, 5 3, 3, 4 6, 5, 4 4, 5, 4 CNN Pool Size Size of the window for max pooling. 2 2 2 2 CNN Activation Function Activation function used in CNN layers. ReLU ReLU ReLU ReLU LSTM Units (1st Layer) The total units present in the first LSTM layer. 100 126 100 66 LSTM Units (2nd Layer) The total units present in the second LSTM layer. 105 37 70 80 LSTM Activation Function Activation function used in LSTM layers. ReLU ReLU ReLU ReLU Dense Layer Activation Function Activation function used in Dense layers. ReLU ReLU ReLU ReLU Output Layer Activation Function The activation function utilized in the output layer of the model. Linear Linear Linear Linear Optimizer Algorithm used for updating the weights. Adam Adam Adam Adam L2 Regularization Regularization applied to the kernel weights matrix. 9.1007e-06 2.7217e-06 1.3918e-05 1.9915e-06 Early Stopping Patience The count of epochs without enhancement after which training process is stopped. 10 10 10 10 Reduce LR Patience The count of epochs without enhancement before reducing the learning rate. 5 5 5 5 Reduce LR Factor Factor by which the learning rate is reduced. 0.5 0.5 0.5 0.5 Minimum Learning Rate Minimum value to which the learning rate can be reduced. 1e-6 1e-6 1e-6 1e-6 minimize RMSE and S-score. 1. Window size for data segmentation. The window size wrepresents the ''number of past time steps'' used for prediction. We tested window sizes w {20, 30, 50, 100} and their effects on RMSE and S-score. A window size of w= 30 achieved the lowest RMSE (10.67) and S-score (192.14), effectively capturing temporal patterns without excessive noise. Larger sizes, like w = 100, increased RMSE, while smaller sizes, such as w= 20, also degraded performance (RMSE: 11.95) due to missing critical patterns. Table 5 shows the sensitivity results for FD001. 2. Learning rate. The learning rate controls the step size during ''gra- dient descent,'' affecting convergence speed and accuracy. We tested learning rates {1 x 10-6, 1.0852 x 10-5, 1 x 10-4, 1 x 10-3} and mea- sured their effects on RMSE, S-score, and convergence time (epochs). The optimal learning rate from the RLHT model was = 1.0852 x 10-5, balancing accuracy and convergence speed.Table 6 presents the sensitivity analysis for FD001. Using the RLHT model, we identified that a window size of 30 and a learning rate of 1.0852 x 10-5 significantly improved accuracy (RMSE = 10.67) and balanced the S-score for the FD001 dataset. This tuning enhances the model's precision and stability, ensuring reliable --- Page 17 --- Reliability Engineering and System Safety 259 (2025) 110919 17 Faizanbasha A. and U. Rizwan Fig. 12. Comparison of true RUL and predicted RUL for subsets (FD001-FD004). Table 4 Comparison of RUL prediction performance. Method FD001 FD002 FD003 FD004 RMSE S-score RMSE S-score RMSE S-score RMSE S-score VLSTM [54] 15.23 250.00 22.87 4532.00 14.53 1523.00 26.11 5627.00 Bi-LSTM-ED [55] 12.45 220.07 27.00 3099.09 17.48 574.00 23.49 3022.00 Bi-LSTM [56] 13.65 295.00 23.18 4130.00 17.14 317.00 24.06 5430.00 DCNN [6] 12.63 411.42 25.53 5755.00 13.10 456.00 23.34 6300.00 BiGRU-TSAM [19] 12.56 213.35 18.94 2246.13 14.45 232.86 23.87 3610.34 AGCNN [57] 12.42 225.61 19.38 2412.00 13.30 397.29 22.58 3392.00 BDL [58] 12.19 267.21 18.49 2007.81 16.07 409.99 19.41 2415.71 IMSDSSN [21] 12.14 261.01 17.40 1775.15 12.57 322.49 19.78 2581.83 SCTA-LSTM [22] 12.10 207.00 17.40 1775.00 12.84 248.00 19.41 3100.00 CNN-Bi-LSTM-AM-BO [32] 11.43 201.26 15.69 1214.47 11.28 181.99 18.35 2627.11 Transformer-based Method + DiffRUL [59] 11.71 199.29 15.90 1162.84 11.77 240.37 18.43 1627.37 PVA-FFG Improved Transformer [29] 11.36 173.89 13.24 714.98 11.80 215.32 15.16 1049.53 DS-STFN [60] 10.92 161.35 13.77 946.34 10.01 150.42 15.53 1079.91 The Proposed Ensemble Model 10.67 157.14 12.35 1201.05 10.32 147.41 14.71 1031.86 Table 5 Sensitivity analysis for window size. Window size (w) RMSE (FD001) S-score (FD001) 20 11.95 215.78 30 10.67 192.14 50 11.12 198.76 100 12.21 225.43 predictions under various conditions. 6.3. Ablation study We conducted an ablation study on our CNN-Transformer-LSTM- SSM ensemble model by systematically removing key modules to eval- uate performance. This study aimed to quantify the impact of the Transformer, LSTM, and SSM on accurately predicting RUL. The goal is to understand how each module contributes to the overall performance and to assess the trade-offs when certain components are excluded. Fig. 13 shows the Ablation Study Cases for the CNN-Transformer- LSTM-SSM model. Subfigures (Fig. 13(a)-(f)) display different configu- rations: (a) complete model, (b) without Transformer, (c) without SSM, (d) without Transformer and SSM, (e) without LSTM, and (f) without LSTM and SSM. These configurations illustrate performance changes when key components are removed. All configurations were evaluated on the ''C-MAPSS dataset'' using RMSE and S-score. In Table 7, we present the results of the performed ablation study, with key observations as follows: * Without Transformer: RMSE increased by 15.15% on average, with a 20.6% increase in FD002 and 10.8% in FD004. This high- lights the Transformer's self-attention mechanism in capturing temporal dependencies. * Without SSM: RMSE increased by 7.9%, highest in FD003 (8.8%) and least in FD004 (2.7%). This shows the SSM's role in stabiliz- ing performance and capturing nonlinear degradation. * Without Transformer and SSM: RMSE increased by 24.95% across datasets. Without these components, the model relies solely --- Page 18 --- Reliability Engineering and System Safety 259 (2025) 110919 18 Faizanbasha A. and U. Rizwan Table 6 Sensitivity analysis for learning rate. Learning rate () RMSE (FD001) S-score (FD001) Convergence time (Epochs) 1 x 10-6 12.43 205.34 65 1.0852 x 10-5 10.67 192.14 50 1 x 10-4 11.82 207.43 40 1 x 10-3 14.98 365.87 20 Fig. 13. Ablation study cases. Table 7 Ablation study results: RMSE and S-score across different configurations. Model FD001 FD002 FD003 FD004 RMSE S-score RMSE S-score RMSE S-score RMSE S-score Full Model (CNN-Transformer-LSTM-SSM) 10.67 157.14 12.35 1201.05 10.32 147.41 14.71 1031.86 Without Transformer 12.10 225.00 14.89 1805.42 11.95 210.23 16.30 1240.35 Without SSM 11.50 194.65 13.87 1452.11 11.23 187.89 15.10 1123.52 Without Transformer and SSM 13.45 290.35 16.45 2007.91 12.50 232.45 17.58 1350.84 Without LSTM 12.85 210.87 14.34 1672.18 11.56 201.22 15.79 1182.79 Without LSTM and SSM 13.50 275.45 15.67 1897.50 12.13 218.54 16.90 1312.67 on the CNN-LSTM framework, neglecting critical temporal and stochastic information, leading to a substantial performance drop. * Without LSTM: RMSE increased by 14.0% on average, indicating the LSTM's importance in modeling sequential dependencies and enhancing the model's ability to predict the RUL. The absence of LSTM results in worse performance, particularly in FD004, where temporal patterns are most critical. * Without LSTM and SSM: RMSE increased by 21.5% on aver- age. The absence of both LSTM and SSM leads to the exclu- sion of both sequential temporal learning and nonlinear degrada- tion modeling, significantly deteriorating the model's predictive capability. This ablation study shows the contribution of Transformer, LSTM, and SSM components in improving model performance and reducing the RMSE and S-score. 6.4. Mission cycles: Analysis of complex multi-segment assignments under multiple scenarios We consider three increasingly complex missions = {M1, M2, M3}. Mission M1, M2, and M3 have 2, 3, and 5 segments, respectively. Here, Mj ,ldenotes the l-th segment of mission Mj. Each segment has a time window, baseline RUL requirement, thrust or certification needs, and environmental conditions. We use four turbofan engines from the NASA C-MAPSS FD001 dataset (Engines #15, #27, #46, and #74), each with scenario-dependent RUL, HPC/HPT limits, certification status, and spare parts requirements. Additionally, three scenarios, = {1, 2, 3}, represent nominal, dusty, and severe conditions. 6.4.1. Missions and segments Table 8 details the missions and segments. Each segment specifies a time window, baseline RUL requirement Dj ,l, thrust requirements (normal/high-thrust), and certification or environmental notes. High- thrust segments and those operating under dusty or severe conditions (2, 3) require additional RUL and HPC/HPT consumption. Addition- ally, the N1 certification in the table ensures engines meet perfor- mance and safety standards for LPC operations, guaranteeing reliable --- Page 19 --- Reliability Engineering and System Safety 259 (2025) 110919 19 Faizanbasha A. and U. Rizwan Table 8 Missions and segments with baseline requirements. Mission segment Time window [tstart j ,l, tend j ,l] Dj ,l(Cycles) Thrust requirement Notes M1,1 [0h, 2h] 40 High-Thrust Normal conditions M1,2 [2h, 5h] 35 Normal Requires N1 certification M2,1 [0h, 3h] 25 Normal Normal conditions M2,2 [3h, 6h] 50 High-Thrust Dusty in 2, severe in 3 M2,3 [6h, 9h] 30 Normal Normal conditions M3,1 [0h, 1h] 20 Normal Normal conditions M3,2 [1h, 3h] 45 High-Thrust High wear rate M3,3 [3h, 6h] 35 Normal Dusty in 2, severe in 3 M3,4 [6h, 8h] 55 High-Thrust N1 certification required M3,5 [8h, 10h] 40 Normal Normal conditions Table 9 Engine RUL, certifications, and spare parts under scenarios. Engine ID RUL (1) RUL (2) RUL (3) L2 i/L3 i N1 certified Spare parts si Engine #15 85 70 60 120/90 Yes s15 = 1 Engine #27 90 65 55 100/80 No s27 = 1 Engine #46 80 60 50 110/75 Yes s46 = 2 Engine #74 95 72 58 95/70 Yes s74 = 1 Table 10 Dynamic failure thresholds for engines under different scenarios. Engine ID Mission(s) Initial threshold (0) Failure threshold (') under three scenarios Rationale 1 (= 0.0752) 2 (= 0.0953) 3 (= 0.1264) Engine #15 M1,1, M3,2 90 67 61 54 Reflects dynamic degradation over 4h mission with mild to severe conditions. Engine #27 M2,1, M2,2, M2,3 115 58 49 37 Accounts for 9h mission duration with moderate wear to accelerated degradation. Engine #46 M1,2, M3,3, M3,4 135 74 63 49 High thresholds adjusted for 8h mission with stricter RUL requirements. Engine #74 M2,2 55 44 41 38 Short 3h mission with rapid degradation across conditions. performance during high-thrust missions. 6.4.2. Engines and scenario effects The Table 9 summarizes the details of four turbofan engines un- der nominal (1), dusty (2), and severe (3) conditions. Higher en- vironmental severity reduces RUL, reflecting faster degradation (see Fig. 14(a)). N1-certified engines reliably handle high-thrust segments. Spare parts (si, e.g., s46 = 2 indicates that Engine #46 has two spare parts available) and HPC/HPT limits are critical for maintenance feasibility and engine reassignment across mission segments. Engine failure threshold. The failure threshold (') for each engine is established using industry reliability standards and empirical analysis of the NASA C-MAPSS FD001 dataset. Examining engines' historical run-to-failure patterns and operational limits, we identify critical RUL values indicating the minimum remaining cycles to safely complete assigned segments. When an engine's predicted RUL falls below ', it is deemed unsafe to continue. Thus, ' guides maintenance scheduling, mission abort decisions, and engine re-engagement strategies, ensur- ing alignment with safety constraints and maintenance protocols. The specific failure thresholds for each engine are detailed in Table 10. The initial threshold (0) is the sum of the cumulative RUL of assigned mission segments and a safety margin, accounting for uncer- tainties, wear, and unforeseen stress. For instance, for Engine #15's missions (M1,1, M3,2), we calculate a combined RUL of 85 cycles and, adding a safety margin of 5 cycles, the initial threshold becomes 90 cycles. This threshold is dynamically adjusted using degradation rate () based on environmental conditions. From empirical testing, historical data, dust levels, temperature extremes, and operational loads, we set = 0.0752 for nominal (1), = 0.0953 for dusty (2), and = 0.1264 for severe (3). Using t= 0 exp(- t), where tis mission duration, we compute failure thresholds (') dynamically. For instance, Engine #27's thresholds are 58, 49, and 37 cycles under 1, 2, and 3. Optimal engine-to-segment assignments. We implement a two-stage stochastic optimization model using a Mixed-Integer Linear Program- ming (MILP) solver to minimize expected costs across scenarios. The objective (Eq. (14)) includes maintenance, fuel, and failure penalties, with constraints (Eq. (15) to Eq. (20)) ensuring feasibility. Binary variables xi,j ,lassign engines to segments, and continuous variables y jcapture scenario-specific outcomes. RUL updates dynamically, mod- eling degradation under varying conditions. Certification and resource constraints ensure feasible scheduling. Scenario probabilities P() en- sure robust solutions. The optimization results, presented in Fig. 14(b), showing optimal engine assignments to mission segments. 6.4.3. Scenario increments for high-thrust and harsh conditions Scenario increments for high-thrust segments are summarized in Table 11. Under 1, no increments apply. Under 2, each high-thrust segment adds +5 RUL cycles and consumes an additional 10 HPC/HPT cycles. Under 3, these increments are doubled, and maintenance resources are limited. Scheduled maintenance actions. Table 12 highlights maintenance scheduling actions under varying conditions, derived using the schedul- ing algorithm (Algorithm 4). 6.4.4. Cost analysis The optimization framework aims to minimize the expected total cost, expressed in currency units, which includes maintenance, fuel consumption, and failure penalties. Table 13 provides a detailed cost breakdown across different scenarios. As scenarios intensify to 3, both maintenance and failure penalties escalate, underscoring increased operational challenges. The optimiza- tion effectively prioritizes maintenance resources to mitigate these costs, ensuring mission-critical segments remain operational. For ex- ample, Engine #15 is consistently maintained after M1,1 across all scenarios, preserving its RUL for high-thrust operations. --- Page 20 --- Reliability Engineering and System Safety 259 (2025) 110919 20 Faizanbasha A. and U. Rizwan Fig. 14. Heatmaps for RUL of four engines across three scenarios and optimal engine-to-mission assignments. Table 11 Scenario increments for high-thrust and harsh conditions. Scenario Additional RUL HPC/HPT per High-Thrust Maintenance constraints 1 +0 cycles +0 HPC/HPT Full crew/spares 2 +5 cycles +10 HPC/HPT Normal crew/spares 3 +10 cycles +15 HPC/HPT Half crew, delayed spares Table 12 Scheduled maintenance actions by scenario. Engine ID Maint. under 1/2 Maint. under 3 Notes E#15 Yes, after M1,1 Yes, earlier for M3,2 Ensures RUL for high-thrust segments E#27 No or minimal Maybe partial if M3 reduced Handles normal wear segments E#46 Yes before M1,2 Challenging under 3 Critical for M3,4 E#74 Possibly after M2,2 Difficult under 3 Adjusts to spares availability Table 13 Cost breakdown by scenario. Scenario Maintenance cost Fuel cost Failure penalty Total cost 1 10,000 50,000 5,000 65,000 2 12,000 55,000 4,000 71,000 3 15,000 60,000 10,000 85,000 6.5. Dynamic mission abort policy: A real-time strategy for preventing failures The key objective of the dynamic mission abort policy compared to static abort policy is that it uses real-time RUL predictions to abort missions when necessary. It helps in terminating catastrophic in-flight engine failures during missions. 6.5.1. Decision rule for abort policy If the predicted RUL of an engine is less than the remaining cycles required for the current and upcoming mission segments, aborting the mission is optimal. Consider mission M2, which consists of three segments (M2,1, M2,2, M2,3) requiring a total of 25 + 50 + 30 = 105 cycles. After 40 cycles, suppose mission M2 completed M2,1 (25 cycles) and partially progressed 15 cycles into M2,2, leaving 35 cycles of M2,2 plus all 30 cycles of M2,3. Thus, 65 cycles remain for mission completion. A(t) = { 1 if RUL(t) < Trem 0 otherwise For example, let Engine #27 (with a current predicted RUL of 30 cycles) be operating on mission M2 at t= 40 cycles. Since 65 cycles are still needed to complete the remaining segments (M2,2 and M2,3), and 30 < 65, aborting the mission prevents potential engine failure. The Table 14 details the predicted RUL, remaining mission segment cycles, shifting and aborting costs, and total expected costs (calculated using Eq. (29)) for each mission decision point. The analysis reveals that aborting missions dynamically when the RUL is insufficient re- sults in a significantly lower total expected cost (15,000) compared to continuing the mission (32,500). 6.6. Post-mission abort analysis and maintenance: Optimizing post-abortion recovery After aborting Engine #27 from mission M2, immediate main- tenance can restore engine health. Let re be the threshold for re- engagement. If maint(t) >=re, the engine is ready to resume operations on subsequent mission segments. Re-engage(t) = { 1 if maint(t) >=re 0 otherwise 6.6.1. Mission shifting and re-engagement: Ensuring continuity after abor- tions If a mission aborts mid-segment, shifting the remaining segments to another engine with adequate RUL can prevent mission failure costs. --- Page 21 --- Reliability Engineering and System Safety 259 (2025) 110919 21 Faizanbasha A. and U. Rizwan Table 14 Dynamic mission abort policy with integrated cost analysis. Time (Cycles) Predicted RUL (Cycles) Remaining segment cycles Abort decision Ctransfer Cabort Ctotal 40 30 65 Abort 10,000 5,000 15,000 50 40 55 Continue - - 32,500 60 35 45 Continue - - 32,500 70 20 35 Abort 10,000 5,000 15,000 80 45 25 Continue - - 32,500 90 25 15 Continue - - 32,500 Table 15 Remaining engines for re-engagement and their RULs. Engine ID Predicted RUL (Cycles) Engine #15 85 Engine #46 80 Engine #74 95 Strategy for mission shifting. Let Trem(Mj) be the cycles needed to complete the remaining segments of mission Mj. Another engine Ei can take over if RULi>=Trem(Mj). Ei= ar g max i (RULisubject to RULi>=Trem(Mj)) . Shifting missions after abortions. Assume Engine #27 aborts mission M2 after 40 cycles, leaving 65 cycles of segments remaining. The Table 15 lists the available engines for re-engagement and their predicted RULs. Engine #74, with 95 RUL cycles, is chosen to complete the remain- ing mission segments (65 cycles required), ensuring mission continuity. For Engine #74 re-engaging, assume a scheduled maintenance cost of 2,200 and an additional fuel cost of 1,600, totaling: Cre = 2, 200 + 1, 600 = 3, 800. By selecting engines with sufficient RUL and managing re-engagement costs, the overall strategy remains cost-effective, ensuring successful completion of mission segments despite aborts. Maintenance and re-engagement of engine #27. Setting re = 0.80, Table 16 shows that after 20 maintenance cycles, Engine #27's health recovers to 0.85, allowing it to re-engage in mission segments if cost- effective. Further, the costs are derived using Eqs. (30) and (32). At lower maintenance cycles (e.g., 10 or 15), no re-engagement occurs, prompting mission shifting and thus higher Ctotal. As maintenance cycles increase and re-engagement becomes feasible, shifting costs are avoided, reducing the overall Ctotal. The implementation of dynamic mission abort policies, driven by real-time RUL predictions, significantly enhances operational reliabil- ity and safety. By proactively aborting missions when engine health is compromised, the strategy prevents catastrophic failures, ensuring mission success and safeguarding critical assets. Collectively, these experimental results validate the proposed SSM- based ensemble deep learning model's effectiveness in accurately pre- dicting RUL across varied and complex operational scenarios. The reinforcement learning-based hyperparameter tuning enhances model performance and stability, while dynamic mission abort policies and mission shifting strategies demonstrate practical applications of RUL predictions in optimizing operational reliability and reducing mainte- nance costs. Additionally, the ensemble model effectively informs mis- sion optimization and maintenance strategies, enhancing operational efficiency, reducing costs, and ensuring higher reliability in predictive maintenance applications. Together, these interconnected innovations highlight the potential of our integrated approach to advance predictive maintenance practices in mission-critical systems, offering substantial advancements to the field of prognostics and health management. 7. Conclusion In this study, we introduced a hybrid ensemble model that combines CNNs, Transformers, LSTMs, and a Smooth Semi-Martingale (SSM) stochastic layer to improve the prediction of Remaining Useful Life (RUL) in industrial equipment. By modeling both deterministic and stochastic degradation processes, our approach addresses challenges posed by nonlinear, nonstationary, and stochastic failures in complex systems. We further enhanced the model's performance and reduced training time by introducing a new Reinforcement Learning-Based Hy- perparameter Tuning (RLHT) method, which adapts to the training process in real-time. Moreover, based on the proposed ensemble model a new predictive maintenance scheduling algorithm has been devel- oped which integrates our model's outputs into maintenance decision- making processes. This algorithm schedules optimal maintenance by considering factors such as maintenance costs, failure risks, and op- erational thresholds, thereby enhancing operational continuity, safety, and cost-effectiveness. Additionally, we introduced a framework for optimizing multi-segment mission cycle assignments and resource man- agement, integrating RUL predictions into multi-stage optimization for dynamic engine allocation, mission adjustments, and maintenance scheduling to minimize costs and mitigate failure risks under com- plex constraints. We also developed a dynamic mission abort policy informed by the predicted RUL, enabling real-time decision-making in mission-critical operations through strategies like mission shifting, re- engagement, and post-abortion analysis, which are crucial for ensuring operational continuity, safety, and cost-effectiveness. Validation on the NASA C-MAPSS dataset demonstrates that our proposed model per- forms better compared to existing state-of-the-art methods, achieving lower RMSE and S-score values across all subsets (FD001-FD004), with RMSE values of 10.67, 12.35, 10.32, and 14.71, respectively. Sensitivity analyses and ablation studies confirm the stability and effectiveness of the proposed framework, highlighting the critical role of important components within the ensemble. By effectively capturing complex degradation patterns through deep learning and stochastic modeling, the proposed model provides more accurate and reliable RUL predic- tions. The integration of dynamic decision-making policies enhances its utility in mission-critical applications, potentially contributing to increased safety, reduced operational costs, and improved efficiency in industrial operations. Despite the promising results, the integration of multiple deep learning architectures and the SSM layer increases computational com- plexity, which may limit real-time deployment in resource-constrained settings. Future work should focus on optimizing the model to reduce computational overhead without compromising accuracy. Expanding the framework to accommodate multi-component systems and explor- ing alternative stochastic modeling techniques could enhance its ap- plicability and robustness. Implementing the dynamic mission abort policy in real-world industrial environments would provide valuable insights for refining the strategy and assessing its impact on operational decision-making. CRediT authorship contribution statement Faizanbasha A.: Writing - review & editing, Writing - origi- nal draft, Visualization, Software, Methodology, Investigation, For- mal analysis, Data curation, Conceptualization. U. Rizwan: Writing - review & editing, Visualization, Validation, Supervision, Resources, Methodology, Data curation. --- Page 22 --- Reliability Engineering and System Safety 259 (2025) 110919 22 Faizanbasha A. and U. Rizwan Table 16 Post-abortion maintenance, re-engagement, and cost analysis for engine #27 (re = 0.80). Time after abort (Cycles) Engine state maint(t) Re-engagement decision Cre Ctotal 10 0.75 No 2,000 8,800 15 0.78 No 2,150 8,950 20 0.85 Yes 2,200 5,200 25 0.90 Yes 2,350 5,350 Funding This research was funded by ''University Grants Commission, Ba- hadurshah Zafar Marg, New Delhi'' under the scheme of CSIR-UGC JRF with ref no: 211610000578. The first author thanks ''Department of Higher Education, Ministry of Education, Govt. of India'' for the financial assistance received during this research work. Declaration of competing interest The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgment The authors express their sincere gratitude to the reviewers and editors for their time and consideration in evaluating this manuscript, contributing to the advancement of scholarly knowledge in this field. Data availability Data will be made available on request. References [1] Zio E. Prognostics and health management (PHM): Where are we and where do we (need to) go in theory and practice. Reliab Eng Syst Saf 2022;218:108119. http://dx.doi.org/10.1016/j.ress.2021.108119. [2] Wu F, Wu Q, Tan Y, Xu X. Remaining useful life prediction based on deep learning: A survey. Sensors 2024;24:3454. http://dx.doi.org/10.3390/ s24113454. [3] Tasci B, Omar A, Ayvaz S. Remaining useful lifetime prediction for predictive maintenance in manufacturing. Comput Ind Eng 2023;184:109566. http://dx.doi. org/10.1016/j.cie.2023.109566. [4] Zhan Y, Kong Z, Wang Z, Jin X, Xu Z. Remaining useful life prediction with uncertainty quantification based on multi-distribution fusion structure. Reliab Eng Syst Saf 2024;251:110383. http://dx.doi.org/10.1016/j.ress.2024.110383. [5] Zhang Q, Liu Q, Ye Q. An attention-based temporal convolutional network method for predicting remaining useful life of aero-engine. Eng Appl Artif Intell 2024;127:107241. http://dx.doi.org/10.1016/j.engappai.2023.107241. [6] Li X, Ding Q, Sun J-Q. Remaining useful life estimation in prognostics using deep convolution neural networks. Reliab Eng Syst Saf 2018;172:1-11. http: //dx.doi.org/10.1016/j.ress.2017.11.021. [7] Ferreira C, Goncalves G. Remaining useful life prediction and challenges: A literature review on the use of machine learning methods. J Manuf Syst 2022;63:550-62. http://dx.doi.org/10.1016/j.jmsy.2022.05.010. [8] Faizanbasha A, Rizwan U. Optimal age replacement time for coherent systems under geometric point process. Comput Ind Eng 2024;190:110047. http://dx.doi. org/10.1016/j.cie.2024.110047. [9] Faizanbasha A, Rizwan U. Optimizing replacement times and total expected discounted costs in coherent systems using geometric point process. Comput Ind Eng 2025;201:110879. http://dx.doi.org/10.1016/j.cie.2025.110879. [10] Faizanbasha A, Rizwan U. Optimizing burn-in and predictive maintenance for en- hanced reliability in manufacturing systems: A two-unit series system approach. J Manuf Syst 2025;78:244-70. http://dx.doi.org/10.1016/j.jmsy.2024.12.002. [11] Lee J, Mitici M. Deep reinforcement learning for predictive aircraft mainte- nance using probabilistic remaining-useful-life prognostics. Reliab Eng Syst Saf 2023;230:108908. http://dx.doi.org/10.1016/j.ress.2022.108908. [12] Ochella S, Shafiee M, Dinmohammadi F. Artificial intelligence in prognos- tics and health management of engineering systems. Eng Appl Artif Intell 2022;108:104552. http://dx.doi.org/10.1016/j.engappai.2021.104552. [13] Wen P, Li Y, Chen S, Zhao S. Remaining useful life prediction of IIoT-enabled complex industrial systems with hybrid fusion of multiple information sources. IEEE Internet Things J 2021;8(11):9045-58. http://dx.doi.org/10.1109/JIOT. 2021.3055977. [14] Nguyen KT, Medjaher K. A new dynamic predictive maintenance framework using deep learning for failure prognostics. Reliab Eng Syst Saf 2019;188:251-62. http://dx.doi.org/10.1016/j.ress.2019.03.018. [15] Mitici M, de Pater I, Barros A, Zeng Z. Dynamic predictive maintenance for multiple components using data-driven probabilistic RUL prognostics: The case of turbofan engines. Reliab Eng Syst Saf 2023;234:109199. http://dx.doi.org/10. 1016/j.ress.2023.109199. [16] Zeng J, Liang Z. A dynamic predictive maintenance approach using probabilistic deep learning for a fleet of multi-component systems. Reliab Eng Syst Saf 2023;238:109456. http://dx.doi.org/10.1016/j.ress.2023.109456. [17] Song Y, Gao S, Li Y, Jia L, Li Q, Pang F. Distributed attention-based temporal convolutional network for remaining useful life prediction. IEEE Internet Things J 2021;8(12):9594-602. http://dx.doi.org/10.1109/JIOT.2020.3004452. [18] Xiang S, Qin Y, Luo J, Pu H, Tang B. Multicellular LSTM-based deep learning model for aero-engine remaining useful life prediction. Reliab Eng Syst Saf 2021;216:107927. http://dx.doi.org/10.1016/j.ress.2021.107927. [19] Zhang J, Jiang Y, Wu S, Li X, Luo H, Yin S. Prediction of remaining useful life based on bidirectional gated recurrent unit with temporal self-attention mechanism. Reliab Eng Syst Saf 2022;221:108297. http://dx.doi.org/10.1016/ j.ress.2021.108297. [20] Yang L, Liao Y, Duan R, Kang T, Xue J. A bidirectional recursive gated dual atten- tion unit based RUL prediction approach. Eng Appl Artif Intell 2023;120:105885. http://dx.doi.org/10.1016/j.engappai.2023.105885. [21] Zhang J, Li X, Tian J, Luo H, Yin S. An integrated multi-head dual sparse self-attention network for remaining useful life prediction. Reliab Eng Syst Saf 2023;233:109096. http://dx.doi.org/10.1016/j.ress.2023.109096. [22] Tian H, Yang L, Ju B. Spatial correlation and temporal attention-based LSTM for remaining useful life prediction of turbofan engine. Measurement 2023;214:112816. http://dx.doi.org/10.1016/j.measurement.2023.112816. [23] Zhang Z, Song W, Li Q. Dual-aspect self-attention based on transformer for remaining useful life prediction. IEEE Trans Instrum Meas 2022;71:1-11. http: //dx.doi.org/10.1109/TIM.2022.3160561. [24] Wang Y, Deng L, Zheng L, Gao RX. Temporal convolutional network with soft thresholding and attention mechanism for machinery prognostics. J Manuf Syst 2021;60:512-26. http://dx.doi.org/10.1016/j.jmsy.2021.07.008. [25] Fu S, Lin L, Wang Y, Guo F, Zhao M, Zhong B, Zhong S. MCA-DTCN: A novel dual-task temporal convolutional network with multi-channel attention for first prediction time detection and remaining useful life prediction. Reliab Eng Syst Saf 2024;241:109696. http://dx.doi.org/10.1016/j.ress.2023.109696. [26] Zhang Y, Su C, Wu J, Liu H, Xie M. Trend-augmented and temporal-featured transformer network with multi-sensor signals for remaining useful life pre- diction. Reliab Eng Syst Saf 2024;241:109662. http://dx.doi.org/10.1016/j.ress. 2023.109662. [27] Xiang F, Zhang Y, Zhang S, Wang Z, Qiu L, Choi JH. Bayesian gated-transformer model for risk-aware prediction of aero-engine remaining useful life. Expert Syst Appl 2024;238:121859. http://dx.doi.org/10.1016/j.eswa.2023.121859. [28] Liu L, Song X, Zhou Z. Aircraft engine remaining useful life estimation via a double attention-based data-driven architecture. Reliab Eng Syst Saf 2022;221:108330. http://dx.doi.org/10.1016/j.ress.2022.108330. [29] Zhou Z, Long Z, Wang R, Bai M, Liu J, Yu D. An aircraft engine remaining useful life prediction method based on predictive vector angle minimization and feature fusion gate improved transformer model. J Manuf Syst 2024;76:567-84. http://dx.doi.org/10.1016/j.jmsy.2024.08.025. [30] Chen C, Zhu ZH, Shi J, Lu N, Jiang B. Dynamic predictive maintenance schedul- ing using deep learning ensemble for system health prognostics. IEEE Sensors J 2021;21(23):26878-91. http://dx.doi.org/10.1109/JSEN.2021.3119553. [31] Wang L, Zhu Z, Zhao X. Dynamic predictive maintenance strategy for system remaining useful life prediction via deep learning ensemble method. Reliab Eng Syst Saf 2024;245:110012. http://dx.doi.org/10.1016/j.ress.2024.110012. [32] Wang L, Chen Y, Zhao X, Xiang J. Predictive maintenance scheduling for aircraft engines based on remaining useful life prediction. IEEE Internet Things J 2024;11(13):23020-31. http://dx.doi.org/10.1109/JIOT.2024.3376715. [33] Lu B, Chen Z, Zhao X. Data-driven dynamic predictive maintenance for a manufacturing system with quality deterioration and online sensors. Reliab Eng Syst Saf 2021;212:107628. http://dx.doi.org/10.1016/j.ress.2021.107628. --- Page 23 --- Reliability Engineering and System Safety 259 (2025) 110919 23 Faizanbasha A. and U. Rizwan [34] Shoorkand HD, Nourelfath M, Hajji A. A hybrid CNN-LSTM model for joint op- timization of production and imperfect predictive maintenance planning. Reliab Eng Syst Saf 2024;241:109707. http://dx.doi.org/10.1016/j.ress.2023.109707. [35] Meng H, Geng M, Han T. Long short-term memory network with Bayesian optimization for health prognostics of lithium-ion batteries based on partial incremental capacity analysis. Reliab Eng Syst Saf 2023;236:109288. http://dx. doi.org/10.1016/j.ress.2023.109288. [36] Wang L, Li B, Zhao X. Multi-objective predictive maintenance scheduling models integrating remaining useful life prediction and maintenance decisions. Comput Ind Eng 2024;197:110581. http://dx.doi.org/10.1016/j.cie.2024.110581. [37] Shi J, Zhong J, Zhang Y, Xiao B, Xiao L, Zheng Y. A dual attention LSTM lightweight model based on exponential smoothing for remaining useful life prediction. Reliab Eng Syst Saf 2024;243:109821. http://dx.doi.org/10.1016/j. ress.2023.109821. [38] Chen J, Gao H, Fang C. Optimal two-stage abort policy considering performance- based missions. Reliab Eng Syst Saf 2025;257:110803. http://dx.doi.org/10. 1016/j.ress.2025.110803. [39] Cheng G, Shen J, Wang F, Li L, Yang N. Optimal mission abort policy for a multi- component system with failure interaction. Reliab Eng Syst Saf 2024;242:109791. http://dx.doi.org/10.1016/j.ress.2023.109791. [40] Zhao X, Li R, Cao S, Qiu Q. Joint modeling of loading and mission abort policies for systems operating in dynamic environments. Reliab Eng Syst Saf 2023;230:108948. http://dx.doi.org/10.1016/j.ress.2022.108948. [41] Meng S, Xing L, Levitin G. Optimizing component activation and operation aborting in missions with consecutive attempts and common abort command. Reliab Eng Syst Saf 2024;243:109842. http://dx.doi.org/10.1016/j.ress.2023. 109842. [42] Levitin G, Xing L, Dai Y. Optimizing time-varying performance and mis- sion aborting policy in resource constrained missions. Reliab Eng Syst Saf 2024;245:110011. http://dx.doi.org/10.1016/j.ress.2024.110011. [43] Levitin G, Xing L, Dai Y. A new self-adaptive mission aborting policy for systems operating in uncertain random shock environment. Reliab Eng Syst Saf 2024;248:110184. http://dx.doi.org/10.1016/j.ress.2024.110184. [44] Fang C, Chen J, Qiu D. Reliability modeling for balanced systems considering mission abort policies. Reliab Eng Syst Saf 2024;243:109853. http://dx.doi.org/ 10.1016/j.ress.2023.109853. [45] Zhao X, Liu H, Wu Y, Qiu Q. Joint optimization of mission abort and system structure considering dynamic tasks. Reliab Eng Syst Saf 2023;234:109128. http://dx.doi.org/10.1016/j.ress.2023.109128. [46] Qiu Q, Maillart LM, Prokopyev OA, Cui L. Optimal condition-based mission abort decisions. IEEE Trans Reliab 2023;72(1):408-25. http://dx.doi.org/10.1109/TR. 2022.3172377. [47] Pan J, Sun B, Wu Z, Yi Z, Feng Q, Ren Y, Wang Z. Probabilistic remaining useful life prediction without lifetime labels: A Bayesian deep learning and stochastic process fusion method. Reliab Eng Syst Saf 2024;250:110313. http: //dx.doi.org/10.1016/j.ress.2024.110313. [48] Lin YH, Ding ZQ, Li YF. Similarity based remaining useful life prediction based on Gaussian process with active learning. Reliab Eng Syst Saf 2023;238:109461. http://dx.doi.org/10.1016/j.ress.2023.109461. [49] Saxena A, Goebel K, Simon D, Eklund N. Damage propagation modeling for aircraft engine run-to-failure simulation. 2008 Int Conf Progn Heal Manag 2008;1-9. http://dx.doi.org/10.1109/PHM.2008.4711414. [50] Qiu Q, Cui L, Wu B. Dynamic mission abort policy for systems operating in a controllable environment with self-healing mechanism. Reliab Eng Syst Saf 2020;203:107069. http://dx.doi.org/10.1016/j.ress.2020.107069. [51] Liu L, Yang J. A dynamic mission abort policy for the swarm executing missions and its solution method by tailored deep reinforcement learning. Reliab Eng Syst Saf 2023;234:109149. http://dx.doi.org/10.1016/j.ress.2023.109149. [52] Liu L, Yang J, Yan B. A dynamic mission abort policy for transportation systems with stochastic dependence by deep reinforcement learning. Reliab Eng Syst Saf 2024;241:109682. http://dx.doi.org/10.1016/j.ress.2023.109682. [53] Sobhi JS. Jet engine turbofan design modelling CATIA V5. 2021, Available from: https://grabcad.com/library/jet-engine-turbofan-design-modelling-catia-v5-1. [54] ElDali M, Kumar KD. Fault diagnosis and prognosis of aerospace systems using growing recurrent neural networks and LSTM. In: 2021 IEEE Aerospace Con- ference (50100). 2021, p. 1-20. http://dx.doi.org/10.1109/AERO50100.2021. 9438432. [55] Yu W, Kim IY, Mechefske C. Remaining useful life estimation using a bidirec- tional recurrent neural network based autoencoder scheme. Mech Syst Signal Process 2019;129:764-80. http://dx.doi.org/10.1016/j.ymssp.2019.05.005. [56] Wang J, Wen G, Yang S, Liu Y. Remaining useful life estimation in prognostics using deep bidirectional LSTM neural network. In: 2018 Prognostics and System Health Management Conference. 2018, p. 1037-42. http://dx.doi.org/10.1109/ PHM-Chongqing.2018.00184. [57] Liu H, Liu Z, Jia W, Lin X. Remaining useful life prediction using a novel feature-attention-based end-to-end approach. IEEE Trans Ind Informatics 2021;17(2):1197-207. http://dx.doi.org/10.1109/TII.2020.2983760. [58] Kim M, Liu K. A Bayesian deep learning framework for interval estimation of remaining useful life in complex systems by incorporating general degrada- tion characteristics. IISE Trans 2021;53(3):326-40. http://dx.doi.org/10.1080/ 24725854.2020.1766729. [59] Wang W, Song H, Si S, Lu W, Cai Z. Data augmentation based on diffusion probabilistic model for remaining useful life estimation of aero-engines. Reliab Eng Syst Saf 2024;252:110394. http://dx.doi.org/10.1016/j.ress.2024.110394. [60] Zhang Q, Yang P, Liu Q. A dual-stream spatio-temporal fusion network with multi-sensor signals for remaining useful life prediction. J Manuf Syst 2024;76:43-58. http://dx.doi.org/10.1016/j.jmsy.2024.07.004.

